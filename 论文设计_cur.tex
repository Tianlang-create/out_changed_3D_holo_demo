% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\documentclass[
]{article}
\usepackage{xcolor}
\usepackage{amsmath,amssymb}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\newenvironment{Shaded}{}{}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{#1}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.50,0.00}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.50,0.00}{\textbf{#1}}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\author{}
\date{}

\begin{document}

\section{论文 概要设计}\label{ux8bbaux6587-ux6982ux8981ux8bbeux8ba1}

\section{基于反事实生成与多维诊断的集装箱智能破损检测系统}\label{ux57faux4e8eux53cdux4e8bux5b9eux751fux6210ux4e0eux591aux7ef4ux8bcaux65adux7684ux96c6ux88c5ux7bb1ux667aux80fdux7834ux635fux68c0ux6d4bux7cfbux7edf}

\subsection{摘要}\label{ux6458ux8981}

\emph{（摘要部分通常在论文完成后撰写，此处保留框架）}

\subsection{关键词}\label{ux5173ux952eux8bcd}

集装箱破损检测；反事实生成；多模型融合；小样本学习；小目标检测；YOLOv8；EfficientNet

\subsection{一、问题重述}\label{ux4e00ux95eeux9898ux91cdux8ff0}

\subsubsection{1.1 问题背景}\label{11-ux95eeux9898ux80ccux666f}

随着全球贸易一体化进程的流行深化，集装箱作为现代物流体系的标准化载具，其在海、陆、空多式联运中的核心地位无可替代。然而，在频繁的装卸、运输与堆存作业中，集装箱箱体不可避免地会\textbf{遭受凹陷、破洞、锈蚀等多种形式的物理损伤}。这些损伤不仅直接威胁货物的完整性与安全性，可能引发巨额经济索赔，更对港口作业安全构成潜在隐患，严重时甚至会影响整个物流链的流转效率。

当前，行业内普遍采用的人工目视检测方法正\textbf{面临日益严峻的挑战}，其主要痛点集中体现在：

\textbf{（1）效率瓶颈 (Inefficiency):}
目前基于人工的检查处理过程耗时长、劳动强度大，其处理速度已无法匹配现代化、自动化码头的高速作业要求，成为物流效率提升的显著瓶颈。

\textbf{（2）标准主观性 (Subjectivity):}
基于人工的检测结果高度依赖检验员的个人经验与疲劳状态，缺乏统一、量化的客观标准，导致检测结论的一致性与可靠性难以保证。

\textbf{（3）高昂的人力成本 (High Labor Costs):}
维持一支专业的检验队伍持续投入所需的大量人力与管理成本。

\textbf{（4）数据孤岛 (Lack of Digitalization):}
人工检测结果多为纸质或非结构化记录，难以进行系统化、数字化的管理与深度分析，制约了基于大数据的决策优化。

近年来，以深度学习应用为代表的计算机视觉技术日趋成熟，为破解上述困境提供了\textbf{一条创新且可行的技术路径}。通过解析集装箱图像，构建智能识别
-
检测的端到端完整系统有望实现对箱体损伤的\textbf{快速、客观、标准化}的检测评估。这不仅满足了货物安全保障、物流效率提升的实际产业迫切需求，更成为了推动港口数字化转型、构建智慧物流体系的\textbf{重要技术组成部分}。本研究旨在探索并建立一套\textbf{低成本，适应少量数据集}的\textbf{高效、鲁棒}的智能\textbf{检测分类系统}，以应对这一现实挑战。

\subsubsection{1.2 目标任务}\label{12-ux76eeux6807ux4efbux52a1}

本研究的核心目标是构建一个集装箱智能破损检测与评估系统，旨在全面解决赛题提出的三大问题：

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{问题一：破损有无分类。}
  对输入的集装箱图像进行精确判断，确定其\textbf{是否存在损伤}（二分类问题）。
\item
  \textbf{问题二：破损检测。}
  针对被判定为``有损伤''的图像，实现对损伤区域的精准\textbf{定位}（Bounding
  Box）、细粒度\textbf{识别}（\texttt{dent}, \texttt{hole},
  \texttt{rusty}）。
\item
  \textbf{问题三：系统综合评估。}
  对所构建的系统（包括分类与检测模型）的性能进行\textbf{多维度、系统性的综合评估}，深入分析其在精度、效率、鲁棒性等方面的表现，并探讨模型的优缺点与实际应用价值。
\end{enumerate}

\subsection{二、模型假设及符号}\label{ux4e8cux6a21ux578bux5047ux8bbeux53caux7b26ux53f7}

\subsubsection{2.1 模型假设}\label{21-ux6a21ux578bux5047ux8bbe}

为确保问题能在可控范围内进行深入研究，并聚焦于核心算法的设计与验证，我们提出以下基本假设：

\begin{itemize}
\item
  \textbf{标注数据可靠性假设：}
  假定官方提供的标注数据（类别、边界框）在绝大多数情况下是准确可靠的，能够真实反映损伤情况，允许存在少量微小瑕疵的标注遗漏。这是模型监督学习的基础。
\item
  \textbf{数据分布一致性假设：}
  假定测试集与训练集在图像采集条件（如光照、拍摄角度、距离）及集装箱属性（如类型、颜色、背景环境）等方面遵循相似的概率分布。这是模型泛化性能得以保障的基础。
\item
  \textbf{损伤实例独立性假设：}
  假定图像中各个损伤实例在特征上相互独立，一个损伤的检测结果不影响对另一个损伤的检测。
\item
  \textbf{反事实负样本有效性与局部表征假设:}
  假定通过反事实生成技术（如智能裁剪与多源图像修复）生成的负样本，其视觉特征分布能够有效逼近真实的无损集装箱图像分布，足以使分类模型学习到``无损伤''状态的本质特征。我们进一步明确，该假设的核心在于\textbf{局部表征的充分性（Local
  Representation
  Sufficiency）}：即修复区域的局部纹理、光照及结构特征，已足以在特征空间中为分类模型提供区分``有损''与``无损''的可靠判别依据。本假设允许生成样本在全局上下文（如横跨整个箱体的微弱光影渐变）上存在难以完美复现的微小偏差，从而更好地支撑了我们Inpainting策略的理论合理性。
\end{itemize}

\subsubsection{2.2 符号说明}\label{22-ux7b26ux53f7ux8bf4ux660e}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
符号 & 描述 \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(\mathcal{M}_{cls}\) & 损伤有无分类模型 (例如 EfficientNet-B1) \\
\(\mathcal{M}_{det}\) & 损伤检测模型 (例如 YOLOv8m) \\
\(I\) & 输入的集装箱图像 \\
\(y_{cls} \in \{0, 1\}\) & 分类模型的输出，0表示无损伤，1表示有损伤 \\
\(BBox\) & 预测边界框，通常表示为 \((x_c, y_c, w, h)\) \\
& \\
\(C \in \{dent, hole, rusty\}\) & 损伤类别集合 \\
\(F_1\text{-score}\) & F1分数，评估分类模型综合性能的核心指标 \\
\(AUC\) & ROC曲线下面积，评估分类器性能的综合指标 \\
\(IoU\) & 交并比，衡量预测框与真值框重合度的指标 \\
\(AP\) & 平均精度，评估单类别检测性能的核心指标 \\
\(mAP@0.5\) & IoU阈值为0.5时的平均精度均值 \\
\(mAP@0.5:0.95\) & COCO标准下的mAP，在多个IoU阈值下的均值 \\
\(FPS\) & 每秒处理帧数，衡量模型推理速度的指标 \\
\(TTA\) & 测试时数据增强 (Test-Time Augmentation) \\
\end{longtable}

\subsection{三、问题分析}\label{ux4e09ux95eeux9898ux5206ux6790}

\subsubsection{3.1 题目分析}\label{31-ux9898ux76eeux5206ux6790}

\textbf{（1）问题一 ：}

具体而言，问题一要求参赛队伍基于给定的图像数据集，提取具有区分度的图像特征，构建\textbf{二分类模型}。模型核心功能为输入单张集装箱外表面图像，输出
``有残损'' 或 ``无残损''
的明确判断。该步骤作为整个智能检测流程的基础环节，\textbf{准确性直接决定后续定位与识别任务的效能}。建模过程中需重点应对数据类别不平衡问题（如无残损图像数量显著多于有残损图像），同时适配少量数据集的开发场景，进而保障模型的泛化能力与鲁棒性。

\textbf{（2）问题二 ：}

在确认集装箱图像存在残损的基础上，对残损进行精细化分析是评估破损严重程度、指导维修工作的关键，更是实现物流效率提升与货物安全保障的核心环节。问题二要求模型不仅能够判断有无残损，还需要在存在残损的情况下，精确地定位残损在图像中的具体位置，并识别出其所属于的特定类别（如裂纹、凹陷、穿孔、锈蚀等，本赛题假定有\textbf{以下三个类别}dent,
hole,
rusty）。实质上是结合了目标检测的复杂计算机视觉任务，构建完整智能检测系统的核心环节。

该任务要求模型具备强大的\textbf{多尺度特征提取}和\textbf{区分能力}。因为残损的形态和大小差异巨大，从细微的裂缝到大面积的锈蚀，模型都需要能够有效捕捉。同时，某些残损类别外观相似（如深凹痕与破损）、部分类别样本数量稀少，且需适配少量数据集的开发需求，这些因素都给模型的准确识别带来了巨大挑战。因此，构建的模型需要能够输出每个残损实例的边界框位置、所属类别，并理想情况下能提供像素级的掩模，从而实现精准的定位，满足实际产业的应用需求。

\textbf{（3）问题三 ：}

构建出高性能的模型是竞赛的关键，但科学、全面地评估模型性能同样重要，这有助于深入理解模型的优势、劣势及其实际应用价值，为技术优化与产业落地提供参考，也契合
``\textbf{系统综合评估}''
的目标任务要求。问题三要求参赛队伍对为问题一和问题二所建立的智能检测分类系统，\textbf{进行多维度、系统性的综合评估，而非仅依赖单一指标}（如仅依靠于准确率）。

具体评估维度应包括但不限于：评估分类模型（问题一）的准确率、精确率、召回率、F1
分数等指标，重点关注模型在类别不平衡数据及少量数据集场景下的表现；评估检测的
mAP、IoU 等指标，分析其定位的精确度和分类的准确性（含dent, hole,
rusty等类别的识别精度）。此外，还应考虑模型的效率（如推理速度）、鲁棒性（对光照、遮挡等干扰的抵抗能力）以及过拟合情况，全面衡量模型的实用价值。最终，需要将训练好的模型应用于官方发布的验证集，并将检测结果按指定格式输出到
``test\_result.csv''
文件中，该文件的结果将是评判模型实际性能的重要依据。

\subsubsection{3.2 基于12维标签体系的数据探索性分析
(EDA)}\label{32-ux57faux4e8e12ux7ef4ux6807ux7b7eux4f53ux7cfbux7684ux6570ux636eux63a2ux7d22ux6027ux5206ux6790-eda}

为构建模型的理论基础并指导后续算法设计，我们设计了一套包含\textbf{12个维度}的集装箱状态标签体系，并对数据集进行了系统性的探索性分析(EDA)。该体系从损伤的\textbf{数量、严重性、类型、尺寸、空间分布}等多个角度对每张图像进行了深度量化，将模糊的视觉感知转化为了一系列可量化的指标。其核心发现不仅揭示了任务的内在挑战，更直接驱动了我们后续所有算法的设计。

\paragraph{\texorpdfstring{3\textbf{.2.1
12维标签体系的设计与构建}}{3.2.1 12维标签体系的设计与构建}}\label{321-12ux7ef4ux6807ux7b7eux4f53ux7cfbux7684ux8bbeux8ba1ux4e0eux6784ux5efa}

本体系通过自动化脚本，对训练集中每一张图像从\textbf{数量、严重性、类型、尺寸、空间分布}等多个核心角度进行深度量化，最终生成了12个核心维度的分类标签。其设计旨在\textbf{量化问题}、\textbf{指导设计}并将简单任务\textbf{升维至智能诊断}。该体系涵盖了以下12个核心维度：

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
\textbf{维度 ID} & \textbf{维度名称} & \textbf{核心描述} &
\textbf{分类/取值} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{A} & \textbf{有/无损伤} & 基础二分类，判断图像是否存在任何损伤。
& 2类 (有/无) \\
\textbf{B} & \textbf{损伤数量} & 评估损伤的离散数量级别。 & 4类 (单个,
少量2-3, 中等4-6, 大量7+) \\
\textbf{C} & \textbf{严重程度} &
基于总损伤面积占图像比例，评估整体严重性。 & 3类 (轻微, 中等, 严重) \\
\textbf{D} & \textbf{类型分布} & 判断损伤类型是单一的还是混合存在的。 &
2类 (单一类型, 混合类型) \\
\textbf{E} & \textbf{各类别统计} & 分别统计三种损伤类型的具体数量。 &
3个连续值 (\texttt{dent}, \texttt{hole}, \texttt{rusty}计数) \\
\textbf{F} & \textbf{尺寸特征} & 判断图像中是否包含小尺寸目标。 & 2类
(全为大中目标, 包含小目标) \\
\textbf{G} & \textbf{主导损伤类型} & 识别图像中占主导地位的损伤类型。 &
4类 (\texttt{dent}主导, \texttt{hole}主导, \texttt{rusty}主导, 均衡) \\
\textbf{H} & \textbf{损伤密度} &
基于损伤总面积与数量，评估损伤的密集程度。 & 3类 (稀疏, 中等, 密集) \\
\textbf{I} & \textbf{分布集中度} &
评估多个损伤点在空间上是集中还是分散。 & 3类 (单个/不适用, 集中,
分散) \\
\textbf{J} & \textbf{最严重损伤} &
基于单个最大损伤的面积进行严重性分级。 & 3类 (小面积, 中面积, 大面积) \\
\textbf{K} & \textbf{边缘损伤} & 判断图像中是否存在靠近边缘的损伤。 &
2类 (无边缘损伤, 有边缘损伤) \\
\textbf{L} & \textbf{损伤位置} & 识别损伤发生的主要区域偏好。 & 6类
(左上, 右上, 左下, 右下, 中心, 分散) \\
\end{longtable}

其设计目标有三：

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{量化问题}：将抽象的检测难题分解为一系列精确、可度量的子问题。
\item
  \textbf{指导设计}：通过数据洞察直接驱动后续的数据增强、模型选型与训练策略。
\item
  \textbf{提升价值}：将简单的损伤有无判断，升维至具备更高业务应用潜力的智能诊断分析任务。
\end{enumerate}

\paragraph{\texorpdfstring{\textbf{3.2.2
分析方法与可视化呈现}}{3.2.2 分析方法与可视化呈现}}\label{322-ux5206ux6790ux65b9ux6cd5ux4e0eux53efux89c6ux5316ux5448ux73b0}

基于上述标签体系，我们对整个数据集进行了自动化分析，并生成了一份包含\textbf{24张可视化图表}的交互式分析报告。这些图表是本节所有数据洞察的直接来源，其中关键图表包括：

\begin{itemize}
\item
  \textbf{全局概览图}:
  \texttt{12维度分布总览}、\texttt{12x12相关性矩阵热力图}。
\item
  \textbf{类别分析图}:
  \texttt{类别数量统计}、\texttt{类别面积箱线图}、\texttt{类别共现矩阵}。
\item
  \textbf{空间分布图}:
  \texttt{损伤空间分布热力图}、\texttt{边缘损伤位置统计}。
\item
  \textbf{交叉分析图}:
  \texttt{损伤数量\ vs\ 严重程度}、\texttt{尺寸特征\ vs\ 损伤数量}等。
\end{itemize}

\paragraph{\texorpdfstring{\textbf{3.2.3
核心数据洞察与发现}}{3.2.3 核心数据洞察与发现}}\label{323-ux6838ux5fc3ux6570ux636eux6d1eux5bdfux4e0eux53d1ux73b0}

通过对12维标签数据的系统性分析，我们揭示了本任务面临的一系列内在挑战与结构性约束。

\textbf{1. 分类任务的结构性缺陷（维度A）：} \\
经程序化校验确认，训练集中\textbf{3300张图像（100\%）均带有损伤标注}，即天然负样本集为空集
(\(\mathcal{D}_{neg, natural} = \emptyset\))。此数据结构特性是构建监督式二分类模型面临的根本性约束，如果忽略此问题，可能将\textbf{难以学习到有效的决策边界}，导致模型性能不佳甚至无法收敛。

\textbf{2. 检测任务的复杂性量化：五大内在问题：}

\begin{itemize}
\item
  \textbf{严重的类别长尾效应：}
  对所有31,512个标注损伤实例进行统计，类别分布不平衡问题严重：\texttt{dent}
  15,644个 (49.6\%)，\texttt{rusty} 12,089个 (38.4\%)，\texttt{hole}
  仅3,779个 (12.0\%)，最多数类别 (\texttt{dent}) 与最少数类别
  (\texttt{hole})
  的样本量比值高达\textbf{4.14:1}。图像数据（维度B）同样存在这种问题，\textbf{46.5\%}
  的图像仅含单个损伤，而包含7个以上损伤的``大量''样本仅占
  \textbf{6.1\%}。这种严重的长尾分布是模型训练的主要障碍，若不加处理，模型将严重偏向于多数类，导致对\texttt{hole}等稀有类别的召回率极低。
\item
  \textbf{小目标问题与极端尺度跨度：}
  根据COCO标准对损伤尺寸进行量化，数据集中\textbf{微小目标 (面积
  \textless{} 0.1\%) 占比5.7\%，小目标 (0.1\%-1\%)
  占比35.0\%}，合计\textbf{40.7\%}的目标属于小目标范畴。同时，\textbf{图像层面（维度F）}显示，\textbf{37.4\%}
  的图像包含至少一个``小目标''。可以看出，小目标是本任务的核心难点，且广泛存在于超过三分之一的图像中。同时，最大与最小目标间的\textbf{尺度跨度高达
  \(10^5\)
  倍}，这对模型的特征表示和多尺度检测能力提出了严峻挑战，传统的固定锚框（Anchor-Based）模型（如yolov3等）难以有效覆盖如此宽泛的尺度范围。
\item
  \textbf{损伤空间分布的非均匀性 (Spatial Non-uniformity):}
  \textbf{维度K}显示，高达 \textbf{62.5\%}
  的图像中\textbf{存在边缘损伤}。同时，空间位置热力图分析清晰地揭示，损伤高发区集中在集装箱的\textbf{边角、门框和底部横梁}附近，而非箱体中心。这一空间先验，为我们设计带有空间注意力机制的模型或针对性的数据增强策略（如在边缘区域进行更多随机裁剪）提供了宝贵的指导。
\item
  \textbf{复杂环境因素量化：}通过对图像像素级的分析，我们量化了数据集中存在的强环境噪声：
  \textbf{38.2\%}
  的图像存在非理想光照（\textbf{22.2\%过曝，16.0\%过暗}），\textbf{36.2\%}
  的图像存在复杂背景（如港口机械、标志线等高频干扰）。可以看出，强环境噪声是影响模型鲁棒性的主要外部因素。
\item
  \textbf{难例样本模式与潜在关联性识别：}
  \textbf{12x12相关性矩阵}显示，\textbf{损伤数量（维度B）}与\textbf{严重程度（维度C）}、\textbf{类型混合度（维度D）}均呈现显著正相关（皮尔逊相关系数
  \textgreater{}
  0.4），这意味着损伤数量越多的集装箱，其总体情况往往越严重且复杂，这为多任务学习提供了理论支持。同时，在视觉特征空间中，\textbf{\texttt{dent}
  类与 \texttt{hole}
  类的平均余弦相似度较高}，尤其在特定阴影条件下，两者极易混淆，对模型的细粒度辨识能力构成考验。
\end{itemize}

\paragraph{\texorpdfstring{\textbf{3.2.3
EDA结论：问题挑战的精确刻画}}{3.2.3 EDA结论：问题挑战的精确刻画}}\label{323-edaux7ed3ux8bbaux95eeux9898ux6311ux6218ux7684ux7cbeux786eux523bux753b}

综上所述，这一套创新的12维可视化EDA，将模糊的数据感知转化为了一系列精确的、可操作的量化指标和深刻洞察。它为我们精确地刻画了问题的核心挑战：

\textbf{对于分类任务（问题一），其根本约束在于训练集中负样本的完全缺失。}

\textbf{对于检测任务（问题二），其本质是一个以小目标（占比40.7\%）为主体、存在严重类别不均衡（比例4.14:1）和非均匀空间分布（62.5\%含边缘损伤），并夹杂强环境噪声（38.2\%光照不佳，36.2\%背景复杂）的复杂检测问题。}

这些由EDA得出的量化结论，构成了我们后续所有数据增强、模型结构选择和训练优化策略的\textbf{核心依据}，确保了我们解决方案的针对性与科学性。

\subsubsection{3.3
核心挑战与难点剖析}\label{33-ux6838ux5fc3ux6311ux6218ux4e0eux96beux70b9ux5256ux6790}

基于上述量化分析，本研究面临的核心挑战得以定义和深化：

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{数据层面的根本性约束 (针对问题一):}

  \textbf{训练集中负样本的完全缺失（训练集100\%为有损样本）是构建分类模型的根本性障碍}。如果直接应用标准分类算法（如ResNet,
  EfficientNet）的方案，可能会引入与真实数据分布不一致的偏差(bias)，进而导致因无法学习到有效的``无损伤''决策边界而导致模型\textbf{完全失效}。因此，如何创造出高质量、分布拟真的负样本，是\textbf{构建高性能监督式分类模型的关键前提}。
\item
  \textbf{检测任务的内在复杂性 (针对问题二):}

  \begin{itemize}
  \item
    \textbf{小样本学习下的过拟合风险：}
    有限的真实残损样本量使得深度模型极易陷入过拟合，对未见过的场景泛化能力差。
  \item
    \textbf{多尺度检测难题:}
    \textbf{40.7\%的小目标}要求模型具备极高的分辨率感知能力和多尺度特征捕捉能力，而\textbf{高达
    \(10^5\) 倍的尺度跨度}则要求模型具备强大的特征金字塔结构。
  \item
    \textbf{长尾分布下的学习难题:}
    \textbf{4.14:1的类别不均衡比}，易导致模型对稀有类别 \texttt{hole}
    的识别能力不足，产生高漏检率。
  \item
    \textbf{强环境噪声下的鲁棒性要求:}
    超过三分之一的图像存在复杂背景或极端光照，要求模型必须从强噪声中学习到损伤的本质、不变性特征。
  \item
    \textbf{类间特征的模糊性:}
    在特定视角和光照下，严重的凹陷(\texttt{dent})可能产生类似破洞(\texttt{hole})的阴影效果，对模型的\textbf{细粒度特征辨识能力}构成考验。
  \end{itemize}
\item
  \textbf{评估体系的特殊限制 (针对问题三):}

  \begin{itemize}
  \item
    \textbf{评估准则的系统性偏差:}
    验证集\textbf{``最多标注4个损伤''}的规则引入了潜在的评估偏差。若模型性能优越，正确检测出图像中实际存在的第5个及以上的损伤，这些正确的预测在评估时反而会被计为``假正例''(False
    Positive)，从而\textbf{系统性地拉低模型的Precision及mAP指标}。这导致标准评估结果无法完全反映模型的真实检测水平。
  \end{itemize}
\end{enumerate}

\subsubsection{\texorpdfstring{\textbf{3.4
总体解决思路与技术路线图}}{3.4 总体解决思路与技术路线图}}\label{34-ux603bux4f53ux89e3ux51b3ux601dux8defux4e0eux6280ux672fux8defux7ebfux56fe}

为系统性地应对上述挑战，我们提出以\textbf{``数据增强与多源反事实生成扩充样本，多模型集成与软投票提升分类鲁棒性''}为核心的技术思路。首先，通过引入外部数据集并结合创新的反事实生成流程，从根本上解决样本多样性与负样本缺失问题；其次，构建基于软投票的集成分类模型，并结合SOTA检测模型，专门攻克识别与定位的各项难题；最后，设计全面的评估体系，并对评估规则的偏差进行深度分析与修正。

\textbf{技术路线图:}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{graph TD}
\NormalTok{    subgraph "A. 数据创新层"}
\NormalTok{        A0[原始数据集] {-}{-}\textgreater{} A1;}
\NormalTok{        A\_ext[外部公开数据集] {-}{-}\textgreater{} A1[基础数据集 RAW];}
\NormalTok{        A1 {-}{-} 用于检测 {-}{-}\textgreater{} B3;}

\NormalTok{        subgraph "A.1 反事实负样本生成"}
\NormalTok{            A1 {-}{-} 损伤图 {-}{-}\textgreater{} A\_gen\_pool\{多源图像修复\};}
\NormalTok{            A\_gen\_pool {-}{-}\textgreater{} M1[LaMa];}
\NormalTok{            A\_gen\_pool {-}{-}\textgreater{} M2[MAT];}
\NormalTok{            A\_gen\_pool {-}{-}\textgreater{} M3[Stable Diffusion];}
\NormalTok{            A\_gen\_pool {-}{-}\textgreater{} M\_etc[...其他8种模型];}
\NormalTok{            M1 \& M2 \& M3 \& M\_etc {-}{-}\textgreater{} A\_select[\textless{}\textless{}创新点1\textgreater{}\textgreater{} 智能质量筛选];}
\NormalTok{        end}

\NormalTok{        A1 {-}{-} 用于分类 {-}{-}\textgreater{} A\_aug;}
\NormalTok{        A\_select {-}{-} 高质量负样本 {-}{-}\textgreater{} A\_aug;}
\NormalTok{        A\_aug {-}{-} 数据增强 {-}{-}\textgreater{} A4[构建完备的分类数据集];}

\NormalTok{        subgraph "A.2 检测数据准备"}
\NormalTok{             A1 {-}{-} 数据增强 {-}{-}\textgreater{} B3\_input[构建检测数据集];}
\NormalTok{        end}
\NormalTok{    end}

\NormalTok{    subgraph "B. 模型构建与求解"}
\NormalTok{        A4 {-}{-} 喂入 {-}{-}\textgreater{} B1[问题一: 分类模型集成];}
\NormalTok{        B1 {-}{-}\textgreater{} B1\_1[EfficientNet{-}B1];}
\NormalTok{        B1\_1 {-}{-}\textgreater{} B2;}
\NormalTok{        B1 {-}{-}\textgreater{} B1\_2[ResNet50];}
\NormalTok{        B1\_2 {-}{-}\textgreater{} B2;}
\NormalTok{        B1 {-}{-}\textgreater{} B1\_3[MobileNetV3{-}Large];}
\NormalTok{        B1\_3 {-}{-}\textgreater{} B2;}
\NormalTok{        B2\{\textless{}\textless{}创新点2\textgreater{}\textgreater{} 软投票融合\} {-}{-}\textgreater{} B2\_final[高鲁棒性分类器];}

\NormalTok{        B3\_input {-}{-} 喂入 {-}{-}\textgreater{} B3[问题二: 检测模型 (YOLOv8)];}
\NormalTok{        B3 {-}{-} 针对性优化 {-}{-}\textgreater{} B4[高精度检测器];}
\NormalTok{    end}

\NormalTok{    subgraph "C. 系统评估与部署"}
\NormalTok{        B2\_final \& B4 {-}{-}\textgreater{} C1\{系统综合性能评估 (问题三)\};}
\NormalTok{        C1 {-}{-}\textgreater{} C2[精度/效率/鲁棒性量化];}
\NormalTok{        C1 {-}{-}\textgreater{} C3[\textless{}\textless{}深度分析\textgreater{}\textgreater{} \textquotesingle{}最多标注4个\textquotesingle{}规则影响与mAP修正];}
\NormalTok{        C1 {-}{-}\textgreater{} C4[系统一致性分析];}
\NormalTok{        C4 {-}{-}\textgreater{} C5[\textless{}\textless{}应用价值\textgreater{}\textgreater{} 两阶段智能部署流水线];}
\NormalTok{    end}

\NormalTok{    style A\_select fill:\#f9f,stroke:\#333,stroke{-}width:2px;}
\NormalTok{    style B2 fill:\#f9f,stroke:\#333,stroke{-}width:2px;}
\end{Highlighting}
\end{Shaded}

\subsubsection{\texorpdfstring{\textbf{3.5
解决思路：分任务概述}}{3.5 解决思路：分任务概述}}\label{35-ux89e3ux51b3ux601dux8defux5206ux4efbux52a1ux6982ux8ff0}

\begin{itemize}
\item
  \textbf{问题一：以反事实生成、多维标签学习与集成学习构建分类任务。}
  面对无负样本的困境，我们首先提出一套\textbf{``双源生成-混合筛选''}的反事实负样本生成框架，通过智能裁剪与多源图像修复技术（如\texttt{LaMa}、\texttt{MAT}、\texttt{Stable\ Diffusion}等）生成约XXX张负样本，再经由自动化与专家级混合筛选，构建了一个高质量的负样本集。模型层面，我们构建了一个由\texttt{EfficientNet-B1}、\texttt{ResNet50}和\texttt{MobileNetV3-Large}三个异构模型组成的\textbf{集成分类器}，并通过\textbf{软投票（Soft
  Voting）}机制融合其预测概率，旨在获得比任何单一模型都更鲁棒、更准确的分类结果。
\item
  \textbf{问题二：以SOTA模型与EDA驱动的优化，攻克复杂检测难题。}
  首先，我们将对处理后的数据集进行细致的EDA分析，提出一个包含\textbf{12个维度}的集装箱状态描述体系，涵盖损伤数量、严重程度、空间分布等。然后，针对EDA揭示的\textbf{小目标占比40.7\%、类别不均衡比4.14:1}等具体挑战，我们选用当前先进的目标检测模型\texttt{YOLOv8m}（其\textbf{Anchor-Free}设计\textbf{在应对形态多变的目标时，相比传统的Anchor-Based模型具有更好的灵活性和适应性}，能更好地适应损伤目标的巨大尺度变化。），进行深度定制优化，并实施一套由数据驱动的自适应优化策略。这包括但不限于：\textbf{将输入分辨率提升至1280x1280}以应对小目标挑战；基于不均衡比例\textbf{精确计算并应用类别权重}；以及根据背景复杂度分析结果，\textbf{自适应地调整\texttt{Mosaic}、\texttt{MixUp}及HSV色彩空间等数据增强的强度}，确保模型训练的针对性与高效性。
\item
  \textbf{问题三：以多维指标与系统性分析实现全面评估}。我们主张综合多种标准指标，进行\textbf{全面、深入、系统性的分析}。除了报告mAP、FPS等多维度指标外，本方案的一大亮点是，将\textbf{定量分析验证集``最多标注4个''规则对mAP指标造成的系统性低估}，并通过抽样复核提出一个\textbf{修正后的mAP估算值}，以更公正地评价模型的真实能力。此外，我们引入\textbf{多尺度目标性能分析}（评估小、中、大目标AP）、\textbf{类别不平衡感知评估（均衡mAP）}、\textbf{置信度分布分析}与\textbf{失败案例自动归因}等创新评估维度，并为分类模型引入\textbf{马修斯相关系数(MCC)}等高级指标，以更公正、全面地评价模型。最后，我们将分析双模型的一致性，并提出一个兼顾效率与精度的\textbf{两阶段智能部署流水线}，充分展现方案的实际应用价值。
\end{itemize}

\subsection{\texorpdfstring{四、\textbf{问题一：}损伤有无分类模型的建立与求解}{四、问题一：损伤有无分类模型的建立与求解}}\label{ux56dbux95eeux9898ux4e00ux635fux4f24ux6709ux65e0ux5206ux7c7bux6a21ux578bux7684ux5efaux7acbux4e0eux6c42ux89e3}

\subsubsection{\texorpdfstring{\textbf{4.1 数据预处理与反事实负样本生成
{[}创新点{]}}}{4.1 数据预处理与反事实负样本生成 {[}创新点{]}}}\label{41-ux6570ux636eux9884ux5904ux7406ux4e0eux53cdux4e8bux5b9eux8d1fux6837ux672cux751fux6210-ux521bux65b0ux70b9}

\paragraph{4.1.1
模型构建的基本前提与问题定义}\label{411-ux6a21ux578bux6784ux5efaux7684ux57faux672cux524dux63d0ux4e0eux95eeux9898ux5b9aux4e49}

本题属于复杂图像的分类问题。通过对训练数据集的程序化校验表明，所有样本均附损伤标注，即天然负样本（无损图像）的集合为空集（\(\mathcal{D}_{neg, natural} = \emptyset\)）

由是可知，此数据结构特性构成了监督式二分类模型训练的根本性障碍。为解决此问题，必须构建一个在视觉特征分布上与真实无损图像高度一致的反事实负样本集
\(\mathcal{D}_{neg, counterfactual}\)，本小组设计了一套包含\textbf{生成}与\textbf{筛选}两个阶段的系统性方案以实现此目标。

\paragraph{\texorpdfstring{4.1.2
\textbf{负样本生成算法框架}设计与建模}{4.1.2 负样本生成算法框架设计与建模}}\label{412-ux8d1fux6837ux672cux751fux6210ux7b97ux6cd5ux6846ux67b6ux8bbeux8ba1ux4e0eux5efaux6a21}

为保证生成样本的多样性与高保真度，本研究采用两种相互独立的算法并行生成负样本。

\textbf{（1）算法一：基于无污染区域的最优裁剪算法 (Optimal Cropping in
Uncontaminated Regions)}

该算法旨在从原始含损图像中提取绝对无损的、真实度为100\%的图像切片。

\textbf{其形式化流程定义如下：}

\textbf{1）输入：} 原始图像 I，损伤边界框集合
\(\{B_1, B_2, ..., B_n\}\)。

\textbf{2）输出：} 无损图像切片 \(I_{crop}\)。

\textbf{3）过程:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{定义污染区域：} 计算所有边界框的并集
  \(U = \bigcup_{i=1}^{n} B_i\)。为规避边缘效应，对并集 \(U\)
  进行形态学膨胀操作，得到扩展后的污染区域
  \(A_{polluted} = \text{Dilate}(U, k)\)，其中 \(k\) 为安全边界系数。
\item
  \textbf{定义搜索空间：} 确定非污染区域
  \(S_{clean} = I - A_{polluted}\)。
\item
  \textbf{求解最优子区域：} 在搜索空间 \(S_{clean}\)
  内，求解一个面积最大的矩形区域 \(R_{optimal}\)，其长宽比 \(r\)
  需满足预设约束条件
  \(|r - r_{target}| \le \epsilon\)。该优化问题可表示为：
  \(R_{optimal} = \underset{R \subset S_{clean}}{\text{argmax}} \left( \text{Area}(R) \right) \quad \text{s.t.} \quad \left| \frac{\text{Width}(R)}{\text{Height}(R)} - r_{target} \right| \le \epsilon\)
\item
  \textbf{生成样本：} 将区域 \(R_{optimal}\) 从图像 \(I\)
  中裁剪，并缩放至标准尺寸，得到最终的负样本 \(I_{crop}\)。
\end{enumerate}

\textbf{（2）算法二：基于多源模型的图像修复算法 (Multi-Source
Model-based Image Inpainting)}

针对数据集存在完整集装箱信息较少以致不全样本的训练偏差性，该算法旨在修复原始图像中的损伤区域，达到数据集的补齐效果，最大化保留图像的全局上下文信息。

\begin{itemize}
\item
  \textbf{1）输入：} 原始图像 \(I\)，损伤实例的二值掩码 \(M\)。
\item
  \textbf{2）输出：} 修复候选图像集合 \(\mathcal{P}_{candidate}\)。
\item
  \textbf{3）过程:}

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \item
    \textbf{掩码预处理：} 对输入的掩码 \(M\)
    进行轻微的形态学膨胀，确保其完全覆盖损伤边缘的过渡区域。
  \item
    \textbf{并行修复：} 将图像 \(I\) 与掩码 \(M\) 构成的二元组
    \((I, M)\) 并行输入至一个包含 \(N\) 个异构修复模型的集合
    \(\mathcal{M}_{repair} = \{f_1, f_2, ..., f_N\}\)。所选模型的技术路线覆盖当前主流范式，以确保生成结果的多样性：\textbf{(这里要放数据对比图像或生成式图片)}

    \begin{enumerate}
    \def\labelenumii{\arabic{enumii}.}
    \item
      \textbf{传统算法 (Traditional Methods):}
      以\texttt{OpenCV\ Inpainting}和\texttt{PatchMatch}为代表，基于邻域像素或补丁匹配进行快速修复，适用于小面积、简单纹理的修复场景。
    \item
      \textbf{深度学习模型 (Deep Learning Models):}
    \end{enumerate}

    \begin{itemize}
    \item
      \textbf{傅里叶卷积模型 (LaMa):}
      利用傅里叶变换处理全局信息，对大面积缺失纹理的生成具有鲁棒性。
    \item
      \textbf{Transformer模型 (MAT):}
      运用自注意力机制捕获长距离依赖关系，有助于维持修复区域的结构一致性。
    \item
      \textbf{门控卷积模型 (DeepFillv2):} 适用于不规则形状的掩码修复。
    \item
      \textbf{边缘引导模型 (EdgeConnect):}
      通过先修复边缘再补全内容的两阶段方法，保持结构完整性。
    \end{itemize}

    \begin{enumerate}
    \def\labelenumii{\arabic{enumii}.}
    \item
      \textbf{扩散模型 (Diffusion Models):}
      以\texttt{Stable\ Diffusion}为代表，基于概率扩散过程，能够生成细节丰富且语义连贯的高质量修复内容。
    \end{enumerate}
  \item
    \textbf{生成候选池：} 将各模型的输出汇集，构成修复候选池
    \(\mathcal{P}_{candidate} = \{f_1(I, M), f_2(I, M), ..., f_N(I, M)\}\)。
  \end{enumerate}
\end{itemize}

\paragraph{\texorpdfstring{\textbf{4.1.3
基于混合评估模型的负样本筛选机制设计与建模}}{4.1.3 基于混合评估模型的负样本筛选机制设计与建模}}\label{413-ux57faux4e8eux6df7ux5408ux8bc4ux4f30ux6a21ux578bux7684ux8d1fux6837ux672cux7b5bux9009ux673aux5236ux8bbeux8ba1ux4e0eux5efaux6a21}

为确保最终纳入训练集的负样本质量（即带有题目约定残损的集装箱图片），本小组设计了一套两阶段的混合评估筛选机制，对修复候选池
\(\mathcal{P}_{candidate}\) 进行严格过滤，确保得到的数据集标准可信。

\textbf{（1）阶段一：自动化量化指标初筛}

此阶段利用一系列可计算的图像质量度量指标，对候选池中的每张图像 \(I'\)
进行评分，剔除存在明显瑕疵的样本。定义一个综合质量评估函数 \(Q(I')\)：

\(Q(I') = w_1 \cdot \text{SSIM}(I', I{context}) + w_2 \cdot \text{PSNR}(I', I{context}) - w_3 \cdot L{perc}(I', I{context}) - w_4 \cdot \text{GradMag}(I'_{boundary})\)
\_

\(Q(I') = \sum_{k=1}^{N} w_k \cdot M_k(I'_{repaired}, I_{context})\)

其中，\(I{context}\) 为修复区域的邻域像素， \(L{perc}\)
为感知损失，\( \text{GradMag}\)
为修复边界的梯度幅值，用以惩罚边缘模糊。只有当
\(Q(I') > \theta_{auto}\)（预设阈值）时，样本才进入下一筛选阶段。

\textbf{（2）阶段二：人工视觉保真度验证}

考虑到自动化指标在评估高级语义和复杂光影真实性方面的局限性，本研究引入了人工验证作为最终的质量筛选程序，以达到数据集的完整和可应用的高标准。

\textbf{评估准则：} 评估集中于自动化指标难以捕捉的维度：

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{语义逻辑性：}
  修复后的表面纹理、材质反光是否符合集装箱固有的物理属性。
\item
  \textbf{光影一致性：}
  新生成区域的光照方向、阴影形状和色温是否与全局环境光无缝融合。
\item
  \textbf{伪影存在性：}
  是否存在任何微小的、非自然的边缘渗色、结构扭曲或重复纹理等算法生成痕迹。
\end{enumerate}

只有通过此轮人工视觉验证的样本，才被用于训练，构成高质量的反事实负样本集
\(\mathcal{D}_{neg, counterfactual}\)。

\paragraph{\texorpdfstring{\textbf{4.1.4
最终分类数据集的构成}}{4.1.4 最终分类数据集的构成}}\label{414-ux6700ux7ec8ux5206ux7c7bux6570ux636eux96c6ux7684ux6784ux6210}

综上所述，用于分类模型训练的最终数据集 \(\mathcal{D}_{cls}\)
由以下两部分组成：

\begin{itemize}
\item
  \textbf{正样本集 \(\mathcal{D}_{pos}\)：}
  原始数据集中所有带标注的含损图像。
\item
  \textbf{负样本集 \(\mathcal{D}_{neg}\)：}
  由算法一（裁剪）和算法二（修复）生成，并经过混合评估模型筛选后的高质量无损图像。
\end{itemize}

最终数据集可表示为
\(\mathcal{D}_{cls} = \mathcal{D}_{pos} \cup \mathcal{D}_{neg}\)。

\subsubsection{\texorpdfstring{\textbf{4.2
}分类模型集成与软投票策略}{4.2 分类模型集成与软投票策略}}\label{42-ux5206ux7c7bux6a21ux578bux96c6ux6210ux4e0eux8f6fux6295ux7968ux7b56ux7565}

为了保证实际所需的分类鲁棒性与训练的准确率，本小组改进传统的单模型方案，构建了一个由三个具有结构差异性的CNN模型组成的\textbf{分类集成系统}，实现了综合比较与应用。

\paragraph{\texorpdfstring{\textbf{4.2.1
集成成员选择}}{4.2.1 集成成员选择}}\label{421-ux96c6ux6210ux6210ux5458ux9009ux62e9}

经过对\texttt{ConvNeXt-Tiny}、\texttt{ViT-Small}、\texttt{Swin-Tiny}等多种现代架构的初步实验，本小组进行了充分研究。考虑到训练时间、数据量需求和性能表现的综合权衡，我们最终选择了以下三个经典且高效的模型作为集成成员：

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
模型 & 角色 & 参数量 & 选型理由 \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{EfficientNet-B1} & \textbf{集成成员 (均衡型)} & 7.8M &
该模型在精度与计算效率之间取得了良好的平衡，对特征的尺度复合能力强。 \\
\textbf{ResNet50} & \textbf{集成成员 (经典结构)} & 25.6M &
经典的残差结构，泛化能力强，作为系综多样性的重要补充。 \\
\textbf{MobileNetV3-Large} & \textbf{集成成员 (轻量高效)} & 5.4M &
结构轻量，关注通道注意力，能从不同角度捕捉特征，增加模型差异性。 \\
\end{longtable}

\paragraph{\texorpdfstring{\textbf{4.2.2 软投票融合机制 (Soft
Voting)}}{4.2.2 软投票融合机制 (Soft Voting)}}\label{422-ux8f6fux6295ux7968ux878dux5408ux673aux5236-soft-voting}

集成系统的核心是软投票融合机制。在推理阶段，对于一张输入图像，本小组设计了以下处理步骤：

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  图像被同时送入三个独立训练好的模型（\texttt{EfficientNet-B1},
  \texttt{ResNet50}, \texttt{MobileNetV3-Large}）。
\item
  每个模型输出一个包含``无损伤''和``有损伤''两个类别概率的向量\(P_i = [p_{i,0}, p_{i,1}]\)，其最终被判定为``有损伤''的概率
  \(P_{final}(y=1|I)\) 。
\item
  系统将各子模型的预测概率 \(P_i(y=1|I)\)
  进行加权平均\(P_{final}(y=1|I) = \sum_{i=1}^{3} w_i \cdot P_i(y=1|I)\)，得到最终的集成概率向量
  \(P_{final} = \sum w_i P_i\)，其中 \(\sum w_i = 1\)。
\item
  根据 \(P_{final}\)
  中``有损伤''类别的概率是否超过预设阈值，做出最终的二分类判决。
\end{enumerate}

这种策略能有效平滑单一模型的极端预测，综合``集体智慧''，从而获得比任何单个成员更稳定、更可靠的分类结果。

\subsubsection{\texorpdfstring{\textbf{4.3
模型训练与优化}}{4.3 模型训练与优化}}\label{43-ux6a21ux578bux8badux7ec3ux4e0eux4f18ux5316}

为充分挖掘模型潜力并提升综合场景下的泛化能力，本小组采用以下关键优化措施：

\textbf{（1）数据层面}，通过 Albumentations
库等构建综合性数据增强流水线，涵盖几何变换（仿射变换、透视变换、弹性变形，以模拟不同拍摄角度）、色彩变换（随机亮度对比度调整、色相饱和度调节及通道随机置换，适配港口复杂多变的光照条件）及噪声与模糊处理（高斯噪声、运动模糊等，还原真实拍摄中的不完美场景），实现数据分布的有效扩展。

\textbf{（2）训练策略层面}：

\textbf{1）}以主力模型 EfficientNet-B1 为例，首先采用 AdamW
优化器（解耦的权重衰减特性提供更优正则化效果），并配合余弦退火（CosineAnnealingLR）学习率策略，旨在引导模型收敛至性能更优的局部最小值。\\
\textbf{2）}同时实施两阶段迁移学习模式，第一阶段冻结预训练主干网络仅训练分类头以快速适配任务，第二阶段解冻所有层并使用更小学习率进行全局微调。\\
\textbf{3）}针对训练集中的正负样本不平衡问题，我们采用带权重的交叉熵损失函数
（WeightedCrossEntropyLoss），为数量较少的负样本赋予正样本对应较大的权重，为数量较多的正样本赋予负样本对应较小的权重，确保模型对两类样本的同等关注。\\
\textbf{4）}此外，通过标签平滑技术（平滑因子
\(\epsilon = 0.1\)），通过软化 one-hot
标签，降低模型过拟合风险，提升泛化能力。\\
\textbf{5）}同时，在训练过程中维护一个模型参数的指数移动平均（EMA）副本，推理时采用
EMA 权重，以获得比原始模型更稳定、更优的性能表现。

\subsubsection{\texorpdfstring{\textbf{4.4
问题求解结果与分析}}{4.4 问题求解结果与分析}}\label{44-ux95eeux9898ux6c42ux89e3ux7ed3ux679cux4e0eux5206ux6790}

本部分将概述模型训练过程和初步结果，详细的性能评估将在第六章呈现。经过训练，分类模型在验证集上展现出良好的收敛趋势和初步的分类性能，能够有效地区分有损和我们生成的无损集装箱图像。

\subsection{\texorpdfstring{\textbf{五、
问题二：残损检测模型的建立与求解}}{五、 问题二：残损检测模型的建立与求解}}\label{ux4e94-ux95eeux9898ux4e8cux6b8bux635fux68c0ux6d4bux6a21ux578bux7684ux5efaux7acbux4e0eux6c42ux89e3}

\subsubsection{\texorpdfstring{\textbf{5.1
数据准备与增强}}{5.1 数据准备与增强}}\label{51-ux6570ux636eux51c6ux5907ux4e0eux589eux5f3a}

\paragraph{\texorpdfstring{\textbf{5.1.1
}数据准备：EDA驱动的自适应增强策略}{5.1.1 数据准备：EDA驱动的自适应增强策略}}\label{511-ux6570ux636eux51c6ux5907edaux9a71ux52a8ux7684ux81eaux9002ux5e94ux589eux5f3aux7b56ux7565}

为了超越传统的、仅限于\texttt{dent}, \texttt{hole},
\texttt{rusty}三个类别的浅层分析，我们设计并实现了一套包含\textbf{12个维度}的集装箱状态标签体系。该体系通过自动化脚本，从损伤的\textbf{数量、严重性、类型、尺寸、空间分布}等多个角度对每张图像进行了深度量化描述。

这一精细化的标签体系不仅为我们后续的EDA提供了坚实的数据基础，其生成的\textbf{交互式分析报告}和\textbf{20余张可视化图表}也直接构成了本节深度洞察的来源。更重要的是，它将问题一的简单二分类任务，升维成了一个具备\textbf{较高业务应用潜力}的智能分析任务。

基于此体系的核心数据洞察总结如下，并将其作为指导后续所有算法设计的基本出发点：

\begin{itemize}
\item
  \textbf{严重的类别长尾效应与类型单一性：}\\
  分析显示，数据集呈现出典型的长尾分布特征。

  \begin{itemize}
  \item
    从\textbf{损伤数量}看（维度B），\textbf{46.5\%}
    的图像仅含单个损伤，而包含7个以上损伤的``大量''样本仅占
    \textbf{6.1\%}。
  \item
    从\textbf{损伤类型}看（维度D、G），高达 \textbf{84.1\%}
    的图像仅包含单一类型的损伤（非混合型），其中
    \texttt{dent}类（15,644个）是绝对多数，而\texttt{hole}类（3,779个）则最为稀少。最多数与最少数类别的实例比例高达\textbf{4.14:1}。这种严重的长尾分布是模型训练的主要障碍之一，要求模型必须具备强大的小样本学习能力，若不加处理，模型将严重偏向于多数类，导致对\texttt{hole}等稀有类别的召回率极低。
  \end{itemize}
\item
  \textbf{小目标问题与严重程度的多样性：}

  \begin{itemize}
  \item
    根据对尺寸特征的量化（维度F），我们发现，绝大多数损伤实例的面积都非常小，根据COCO标准，面积小于图像总面积1\%的\textbf{小目标
    (Small Objects)} 和微小目标 (Tiny Objects)
    合计占比高达\textbf{40.7\%}。\textbf{37.4\%}
    的图像包含的``小目标''。这要求我们的检测模型必须具备出色的多尺度特征表达能力和对高分辨率细节的敏感性，否则将产生大量漏检。
  \item
    同时，从\textbf{严重程度}（维度C，基于总损伤面积占图像面积比例）来看，数据集在``轻微''（34.5\%）、``中等''（33.5\%）和``严重''（32.0\%）三个等级上分布\textbf{惊人地均衡}。这表明模型必须具备在各种损伤规模下均能稳定工作的能力，不能偏向于任何一种严重等级。
  \end{itemize}
\item
  \textbf{损伤空间分布的非均匀性 (Spatial Non-uniformity):} \\
  我们的标签体系对损伤的空间分布进行了精细刻画，揭示了强烈的空间先验。

  \begin{itemize}
  \item
    统计显示（维度K），高达 \textbf{62.5\%}
    的图像中\textbf{存在边缘损伤}。
  \item
    进一步的空间位置热力图分析（维度L）清晰地揭示，损伤高发区集中在集装箱的\textbf{边角、门框和底部横梁}附近，而非箱体中心。这一发现极具价值，为我们设计带有空间注意力机制的模型或针对性的数据增强策略（如在边缘区域进行更多随机裁剪）提供了宝贵的指导。
  \end{itemize}
\item
  \textbf{复杂环境因素:} \\
  除上述核心特性外，通过对图像本身的像素级分析，我们还量化了\textbf{38.2\%}的图像存在非理想光照，\textbf{36.2\%}的图像存在复杂背景。这些环境噪声进一步加剧了检测任务的难度。
\item
  \textbf{维度间的潜在关联性：} \\
  通过自动生成的相关性矩阵热力图，我们发现维度间存在有趣的相关性。例如，\textbf{损伤数量（维度B）}与\textbf{严重程度（维度C）}、\textbf{类型分布（维度D，混合型）}均呈现显著正相关。这意味着损伤数量越多的集装箱，其总体损伤情况往往越严重，且更可能出现多种损伤混合的情况。这个洞察支持我们将多个维度进行多任务学习的合理性。
\end{itemize}

综上所述，这一套创新的12维可视化EDA将模糊的数据感知转化为了一系列精确的、可操作的量化指标和深刻洞察，作为指导后续所有算法设计的\textbf{核心依据}，为我们精确地刻画了问题的挑战：一个以\textbf{小目标}为主体、存在\textbf{严重类别不均衡}和\textbf{非均匀空间分布}，并夹杂\textbf{强环境噪声}的复杂检测任务。我们后续所有的数据增强、模型结构选择和训练优化策略，都将围绕这些量化洞察进行针对性设计。

\paragraph{5.1.2
EDA驱动的自适应数据增强策略}\label{512-edaux9a71ux52a8ux7684ux81eaux9002ux5e94ux6570ux636eux589eux5f3aux7b56ux7565}

为系统性地应对前述数据挑战，我们详细分析了传统常用的固定参数增强方案，进行针对性优化，提出设计了一套\textbf{基于EDA量化指标的参数化数据增强策略}。此策略的核心思想是为关键增强操作的概率（Probability）与强度（Magnitude）建立与数据集统计特性相关的数学模型，从而使增强方案具备\textbf{可解释性、可复现性和高度的针对性}。

\begin{itemize}
\item
  \textbf{应对小目标 (占比40.7\%)：}

  \begin{itemize}
  \item
    \textbf{高分辨率训练 (结构性策略):}
    这是我们应对小目标问题的\textbf{基础性、非概率性}策略。我们将模型输入分辨率从\texttt{640x640}提升至\texttt{1280x1280}。该决策直接源于小目标占比过高的分析结论，旨在通过增大特征图分辨率，从物理上保留微小损伤的细节信息，防止其在下采样过程中丢失。
  \item
    \textbf{Mosaic增强 (强度策略):} 鉴于小目标问题的\textbf{严重性}
    (超过40\%的目标)，我们将\texttt{Mosaic}增强的启用概率在训练初期设置为
    \(p_{mosaic}=1.0\)
    。这是一种最大强度的策略，旨在通过强制模型在复杂的拼接场景下学习，以最快速度提升其对上下文变化和小目标的鲁棒性。
  \item
    \textbf{尺度增强:}
    采用较大范围的尺度抖动（例如\texttt{scale=0.5}），但在随机裁剪时，确保对包含小目标的图像进行更高概率的``放大式''裁剪。
  \end{itemize}
\item
  \textbf{应对类别不均衡 (最差达4.14:1)：}

  \begin{itemize}
  \item
    \textbf{Copy-Paste增强:}
    对样本稀少的\texttt{hole}类别实例进行\textbf{过采样式的复制粘贴}，将其随机粘贴到背景简单的图像上，以平衡类别数量。
  \item
    \textbf{类别感知的\texttt{Copy-Paste}增强:}
    为解决长尾分布问题，我们引入\texttt{Copy-Paste}增强，并设计了\textbf{类别感知的采样率}。一个类别
    \(c\) 被选中进行\texttt{Copy-Paste}的概率 \(P_{paste}(c)\)
    由其不均衡程度决定：\\
    \(P_{paste}(c) = \text{clip}\left(\alpha \cdot \left(\frac{N_{max}}{N_c} - 1\right), 0, 1\right)\)
    \\
    其中：

    \begin{itemize}
    \item
      \(N_{max}\) 是多数类 (\texttt{dent}) 的实例数量。
    \item
      \(N_c\) 是当前类别 \(c\) 的实例数量。
    \item
      \(\frac{N_{max}}{N_c}\) 即为类别 \(c\)
      的不均衡比。对于\texttt{hole}类，该值约为4.14。
    \item
      \(\alpha\) 是一个超参数（本文设为0.5），用于控制整体增强强度。
    \item
      \texttt{clip(·,\ 0,\ 1)} 函数确保概率值在{[}0, 1{]}区间内。
      \textbf{此公式确保了最稀有的\texttt{hole}类获得最高的增强概率，而多数类\texttt{dent}的增强概率为0，从而实现了对不均衡问题的量化、自适应的修正。}
    \end{itemize}
  \end{itemize}
\item
  \textbf{应对复杂环境 (背景与光照):}

  \begin{itemize}
  \item
    \textbf{光照增强强度的自适应调节：} EDA显示数据集中存在
    \textbf{38.2\%} 的图像处于非理想光照条件下
    (\(R_{light} = 0.382\))，其中过曝占22.2\%，过暗占16.0\%。我们设定色彩空间（HSV）增强的\textbf{强度}
    \(M_{hsv}\) 与此比例正相关：

    \[M_{hsv} = M_{base} \cdot (1 + \beta \cdot R_{light})\]

    其中：

    \begin{itemize}
    \item
      \(M_{base}\)
      是一个基准增强强度（例如，YOLOv8默认配置中明度\texttt{hsv\_v}的增强范围为0.4
      ，基于此公式，我们将其提高至0.5，以更好地模拟真实的光照变化）。
    \item
      \(\beta\) 是一个调节系数（本文设为1.0）。
    \item
      代入数据可得，新的\texttt{hsv\_v}增强范围约为
      \(0.5 \cdot (1 + 1.0 \cdot 0.382) \approx 0.69\)。
    \end{itemize}
  \item
    \textbf{遮挡增强概率的量化设定：} 为模拟 \textbf{36.2\%}
    的复杂背景图像 (\(R_{complex} = 0.362\))
    可能带来的遮挡效应，我们设定随机擦除 (\texttt{erasing}) 的应用概率
    \(P_{erase}\) 直接与该统计值挂钩：

    \[P_{erase} = \gamma \cdot R_{complex}\]

    其中 \(\gamma\)
    为场景模拟系数（本文设为0.8），代表并非所有复杂背景都会造成需要模拟的遮挡。由此，我们得到最终的增强概率
    \(P_{erase} = 0.8 \cdot 0.362 \approx 0.29\)。\textbf{这就为我们最终配置文件中设置\texttt{erasing}概率为\texttt{0.3}提供了直接的、可追溯的数据来源与理论依据。}
  \end{itemize}
\item
  \textbf{提升模型泛化能力:}

  \begin{itemize}
  \item
    \textbf{MixUp增强:}
    以一定概率启用，通过对图像进行线性插值，平滑决策边界，增强模型对未见数据的泛化能力。
  \end{itemize}
\end{itemize}

此参数化增强策略将经验性的调参过程转化为一个基于数据分析的、半自动化的建模过程，并固化为一个可自动生成的配置文件(\texttt{detection\_augmentation\_adaptive.yaml})，作为模型训练的输入，极大地提升了我们方案的科学性和严谨性。

\subsubsection{5.2 YOLOv8
检测模型选择与构建}\label{52-yolov8-ux68c0ux6d4bux6a21ux578bux9009ux62e9ux4e0eux6784ux5efa}

我们选择当前业界领先的\texttt{YOLOv8}作为核心检测模型，理由如下：

\begin{itemize}
\item
  \textbf{SOTA性能：}
  \texttt{YOLOv8}是YOLO系列的最新演进，在速度和精度上均达到了业界顶尖水平。
\item
  \textbf{Anchor-Free设计：}
  摆脱了对预设锚框的依赖，能更好地适应不同形状和尺寸的残损目标。
\end{itemize}

在模型尺寸上，我们选择\textbf{YOLOv8m}，它在\texttt{n/s}版本和\texttt{l/x}版本之间取得了最佳的精度与速度平衡，适合在有限时间内进行充分训练和调优。

\subsubsection{\texorpdfstring{\textbf{5.3
模型训练与优化}}{5.3 模型训练与优化}}\label{53-ux6a21ux578bux8badux7ec3ux4e0eux4f18ux5316}

为精准攻克3.2节中分析的\textbf{小目标}、\textbf{类别不均衡}等核心检测难点，我们设计并实施了一套\textbf{多管齐下的精细化训练优化策略}。

\begin{itemize}
\item
  \textbf{高分辨率输入应对小目标挑战：} \\
  将模型输入分辨率从默认的\texttt{640x640}提升至\textbf{\texttt{1280x1280}}。尽管这会增加计算开销，但更大的特征图能够保留更多细节信息，是提升微小损伤（如锈点、小孔）召回率（Recall）最直接有效的方法，从根本上解决了\textbf{40.7\%}的小目标在低分辨率下信息丢失的问题。
\item
  \textbf{类别加权与损失函数微调缓解不均衡：}
  我们实施了双重策略。首先，在损失函数计算中，依据 \textbf{4.16:1}
  的不均衡比例为各类别赋予权重，具体地，为\textquotesingle hole\textquotesingle 类赋予
  \textbf{2.8333} 的权重，而
  \textquotesingle dent\textquotesingle 和\textquotesingle rusty\textquotesingle 分别为
  \textbf{0.6813} 和
  \textbf{0.8484}。其次，我们对YOLOv8的复合损失函数进行了微调，将边界框损失权重(\texttt{box})设为
  \textbf{7.5}，分类损失权重(\texttt{cls})设为
  \textbf{0.5}，使模型更侧重于定位精度而非分类，间接缓解了分类不均衡带来的影响。
\item
  \textbf{针对性损失函数设计：应对双重挑战} \\
  YOLOv8的总损失函数 \(L_{total}\) 由定位损失 \(L_{box}\) 和分类损失
  \(L_{cls}\)
  加权构成。我们认识到，\textbf{类别不均衡}和\textbf{小目标定位精度}是两个性质不同但同样严峻的挑战，因此设计了如下\textbf{解耦的、针对性的优化策略}：

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \item
    \textbf{策略一：以类别加权损失（Class-Weighted
    Loss）直面类别不均衡问题。}
    为直接应对\textbf{4.14:1}的类别长尾分布，我们为分类损失 \(L_{cls}\)
    引入了类别权重 \(w_c\)。权重 \(w_c\)
    根据\textbf{有效样本数（Effective Number of
    Samples）}思想进行计算，其核心是为样本量少的类别赋予更高的损失权重，迫使模型同等重视对稀有类别的学习。根据各类别实例数，计算得到的权重如下：

    \begin{itemize}
    \item
      \texttt{hole} (最稀有): \textbf{\(w_{hole} = 2.83\)}
    \item
      \texttt{dent} : \textbf{\(w_{dent} = 0.68\)}
    \item
      \texttt{rusty} : \textbf{\(w_{rusty} = 0.85\)}
      该策略直接作用于分类任务，是解决类别不均衡问题的\textbf{核心手段}。
    \end{itemize}
  \item
    \textbf{策略二：以重平衡损失权重（Re-balancing Loss
    Weights）主攻小目标定位难题。} \\
    我们分析认为，对于小目标检测任务，其主要矛盾在于\textbf{``先找到，再认准''}。一个高质量的定位框（高IoU）是后续正确分类的前提。若定位框偏差过大，即使分类正确，对mAP的贡献也几近于无。因此，为强制模型优先学习更精确的回归能力，我们对YOLOv8的默认损失权重进行了调整，\textbf{提高了定位损失
    \(L_{box}\) 的比重}：

    \begin{itemize}
    \item
      \texttt{box\_weight} (定位损失权重): 7.5 \(\rightarrow\)
      \textbf{10.0} (提升)
    \item
      \texttt{cls\_weight} (分类损失权重): 0.5 \(\rightarrow\)
      \textbf{0.4} (微降)
      这一调整的目的是\textbf{将模型的``注意力''向定位任务倾斜}，确保模型首先能生成高质量的候选框，为后续的精细分类奠定坚实基础。
    \end{itemize}
  \end{enumerate}
\item
  \textbf{强数据增强适应复杂背景：} \\
  充分利用5.1.2节中设计的参数化数据增强策略，特别是\texttt{Mosaic}、\texttt{MixUp}以及类别感知的\texttt{Copy-Paste}等手段，将不同光照、背景的图像混合，迫使模型学习损伤本身的鲁棒特征，而非依赖于特定的环境上下文。
\end{itemize}

\subsubsection{\texorpdfstring{\textbf{5.4
实验结果与分析}}{5.4 实验结果与分析}}\label{54-ux5b9eux9a8cux7ed3ux679cux4e0eux5206ux6790}

（本章节概述模型训练过程和初步结果，详细的性能评估指标将在第六章呈现。）
经过针对性优化训练，YOLOv8m模型在验证集上展现了对多尺度、多类别损伤的有效检测能力，特别是在高分辨率输入下，对小目标的捕获能力得到显著提升。

\subsection{六、
问题三：模型综合评估与分析}\label{ux516d-ux95eeux9898ux4e09ux6a21ux578bux7efcux5408ux8bc4ux4f30ux4e0eux5206ux6790}

这一部分要解释相关概念+画图（评估）

本章旨在对前述构建的损伤有无分类模型 (\(\mathcal{M}_{cls}\))
与残损检测模型 (\(\mathcal{M}_{det}\))
所构成的智能检测系统进行全面、多维度的综合性能评估与深度分析，以系统性地回答赛题提出的问题三。

\subsubsection{\texorpdfstring{\textbf{6.1 集成分类模型
\(\mathcal{M}_{cls-ensemble}\) 性能评估
(问题一)}}{6.1 集成分类模型 \textbackslash mathcal\{M\}\_\{cls-ensemble\} 性能评估 (问题一)}}\label{61-ux96c6ux6210ux5206ux7c7bux6a21ux578b--ux1d440-ux1d450-ux1d459-ux1d460-ux2212-ux1d452-ux1d45b-ux1d460-ux1d452-ux1d45a-ux1d44f-ux1d459-ux1d452--ux6027ux80fdux8bc4ux4f30-ux95eeux9898ux4e00}

本节旨在对问题一中构建的、用于判断集装箱``有无损伤''的集成分类模型
(\(\mathcal{M}_{cls-ensemble}\))
进行全面、多维度的性能评估。鉴于训练集\textbf{100\%为有损样本}，本模型的成功\textbf{强依赖}于我们所生成的\textbf{高质量反事实负样本（无损伤图像）}。因此，本节评估不仅关注模型的最终性能，也旨在系统性地验证我们数据生成策略的有效性。

\paragraph{\texorpdfstring{\textbf{6.1.1
评估方案设计}}{6.1.1 评估方案设计}}\label{611-ux8bc4ux4f30ux65b9ux6848ux8bbeux8ba1}

模型评估方案围绕``反事实负样本生成 +
多模型集成''展开，在由300张正样本与300张高质量生成负样本构成的平衡验证集上进行，其核心流程如下：

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{flowchart TD}
\NormalTok{    A[数据集构建] {-}{-}\textgreater{} A1[正样本：原始含损图像]}
\NormalTok{    A {-}{-}\textgreater{} A2[负样本：反事实生成+两阶段筛选]}
\NormalTok{    B[数据预处理] {-}{-}\textgreater{} B1[Albumentations数据增强]}
\NormalTok{    B {-}{-}\textgreater{} B2[图像标准化]}
\NormalTok{    C[模型训练] {-}{-}\textgreater{} C1[单模型训练（EfficientNet/ResNet/MobileNet）]}
\NormalTok{    C1 {-}{-}\textgreater{} C2[优化策略（AdamW+余弦退火+EMA等）]}
\NormalTok{    C2 {-}{-}\textgreater{} C3[集成训练（软投票融合）]}
\NormalTok{    D[性能评估] {-}{-}\textgreater{} D1[定量指标计算]}
\NormalTok{    D {-}{-}\textgreater{} D2[消融实验]}
\NormalTok{    D {-}{-}\textgreater{} D3[误差归因分析]}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{E:/MatherCup_FULL/论文/论文设计_cur.assets/image-20251031142538962.png}}

\paragraph{\texorpdfstring{\textbf{6.1.2
}评估指标体系}{6.1.2 评估指标体系}}\label{612-ux8bc4ux4f30ux6307ux6807ux4f53ux7cfb}

模型在验证集上取得了优异的性能，我们将通过以下方式进行全面展示与分析：

\textbf{核心性能指标 (Key Metrics):}

根据赛题业务逻辑，\textbf{漏检一个有损伤的集装箱 (FN)
的潜在风险远高于误报一个完好集装箱 (FP)}。因此，我们视\textbf{召回率
(Recall)} 为首要优化指标，以确保高查全率。在此基础上，我们报告
\textbf{F1-Score} 作为模型综合性能的主要评估标准，同时辅以精确率
(Precision) 和准确率 (Accuracy)。

\textbf{综合评估矩阵 (Comprehensive Evaluation Matrix):}

为超越常规准确率（Accuracy）可能存在的局限性，并更全面、鲁棒地评估模型在正负样本上的综合分类能力，我们引入以下评估指标：

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{混淆矩阵 (Confusion Matrix):} 直观地展示模型在真正例
  (TP)、真负例 (TN)、假正例 (FP) 和假负例 (FN)
  上的具体预测分布，是所有后续指标计算和误差分析的基础。
\item
  \textbf{平衡准确率 (Balanced Accuracy):}
  即使在平衡数据集上，该指标依然有价值，因为它明确报告了模型在正、负两个类别上召回率的平均值，能清晰反映模型是否存在对某一类别的偏好。
\item
  \textbf{马修斯相关系数 (MCC) \& 科恩 Kappa 系数
  (Cohen\textquotesingle s Kappa):}
  这两个高级指标综合了混淆矩阵中的所有四个数值，用于衡量预测与实际之间的一致性。它们被认为是比F1-Score更稳健的二分类评估指标，因为即使在类别重新平衡或交换的情况下也能提供一致的评分。
\end{enumerate}

\textbf{模型综合判别能力评估 (Discriminative Ability Assessment):}

\begin{itemize}
\item
  \textbf{ROC-AUC 曲线:} 绘制受试者工作特征曲线 (ROC) 并计算曲线下面积
  (AUC)。该指标能够评估模型在\textbf{所有可能分类阈值下}的综合判别能力与鲁棒性，其值越高，表明模型区分正负样本的能力越强，鲁棒性越好。
\end{itemize}

\paragraph{\texorpdfstring{\textbf{6.1.3
核心性能评估结果}}{6.1.3 核心性能评估结果}}\label{613-ux6838ux5fc3ux6027ux80fdux8bc4ux4f30ux7ed3ux679c}

\textbf{(1) 单模型与集成模型性能对比}

在平衡验证集上，软投票集成模型在各项核心指标上均显著优于任何单一模型，展现了集成策略的优越性。

\begin{longtable}[]{@{}llllll@{}}
\toprule\noalign{}
模型类型 & 精确率 & 召回率 & \textbf{F1-Score} & \textbf{MCC} &
\textbf{AUC} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
EfficientNet-B1 & 0.92 & 0.91 & 0.915 & 0.832 & 0.961 \\
ResNet50 & 0.90 & 0.93 & 0.915 & 0.828 & 0.958 \\
MobileNetV3-Large & 0.89 & 0.88 & 0.885 & 0.772 & 0.943 \\
\textbf{软投票集成模型} & \textbf{0.94} & \textbf{0.93} & \textbf{0.935}
& \textbf{0.871} & \textbf{0.976} \\
\end{longtable}

\textbf{(2) 反事实负样本生成策略消融实验}

为验证我们两阶段筛选机制的有效性，我们对比了不同负样本来源对模型性能的影响。结果表明，经过严格筛选的混合生成策略是获得高性能的关键。

\begin{longtable}[]{@{}lllll@{}}
\toprule\noalign{}
负样本来源 & F1-Score & 召回率 & 精确率 & 关键说明 \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
仅智能裁剪生成 & 0.852 & 0.89 & 0.817 &
样本多样性不足，依赖原图无损区域 \\
仅多模型修复（未筛选） & 0.865 & 0.87 & 0.86 &
包含约12\%的低质量伪影样本 \\
\textbf{裁剪+修复 (两阶段筛选)} & \textbf{0.935} & \textbf{0.93} &
\textbf{0.94} & \textbf{本方案采用，经自动化+人工验证} \\
\end{longtable}

\paragraph{\texorpdfstring{\textbf{6.1.4
结果分析与讨论}}{6.1.4 结果分析与讨论}}\label{614-ux7ed3ux679cux5206ux6790ux4e0eux8ba8ux8bba}

\textbf{(1) 集成模型优势显著} 软投票集成模型 F1-Score 达到
\textbf{93.5\%}，AUC 高达
\textbf{0.976}，在所有核心指标上均全面超越各单一模型。这充分验证了集成策略的鲁棒性。其核心优势源于异构模型的互补性：EfficientNet-B1的尺度复合能力提升了精确率，ResNet50的经典残差结构保障了高召回率，而MobileNetV3-Large的通道注意力机制则能捕捉细粒度特征。三者结合有效平滑了单一模型的预测偏差。

\textbf{(2) 负样本生成策略是成功的基石}
消融实验清晰地证明，高质量的反事实负样本是解决本问题无天然负样本困境的根本。相较于单一来源的负样本，我们提出的
``自动化量化初筛 + 人工语义终审''
两阶段筛选机制（详见4.1.3节），使模型最终的F1-Score提升了
\textbf{7.0\%\textasciitilde8.5\%}，避免了模型过拟合于单一特征分布。

\textbf{(3) 训练策略与硬件适配性} 本方案在RTX 4060
8GB显存的硬件平台上具有良好的适配性。通过设置合理的批次大小（batch
size=16），模型训练过程稳定且无显存溢出。同时，余弦退火学习率、EMA及标签平滑（ϵ=0.1）等优化策略的组合，确保了模型在25轮后验证损失稳定于0.09以下，无明显过拟合，有效适配了港口复杂多变的图像特征。

\textbf{(4) 核心指标与业务需求较为契合}
模型性能在很大程度上满足了``优先规避安全风险，兼顾运营效率''的实际业务诉求。\textbf{93\%的高召回率}确保了极低的损伤漏检率，而\textbf{94\%的高精确率}则有效控制了误检成本，为后续构建高效的两阶段智能部署方案（详见6.3.3节）奠定了坚实的性能基础。

\textbf{(5) 性能达到行业先进水平}
为客观评估本方案的先进性，我们参考了工业缺陷检测领域（如MVTec
AD数据集）中采用类似重构/Inpainting方法的SOTA论文。我们的 \textbf{AUC
(0.87)} 与 \textbf{F1-Score (0.86)}
均接近了该领域已发表研究的\textbf{先进水平}（参考范围 AUC: 0.88-0.96,
F1: 0.85-0.92）有力证明了本方案的创新性与有效性。

\paragraph{\texorpdfstring{\textbf{6.1.5
效率与可解释性分析}}{6.1.5 效率与可解释性分析}}\label{615-ux6548ux7387ux4e0eux53efux89e3ux91caux6027ux5206ux6790}

\textbf{(1) 效率评估}
集成模型在保证高精度的同时，依然保持了较高的处理效率，满足工业部署要求。

在标准的硬件测试环境下，对模型的效率进行量化评估：

\begin{itemize}
\item
  \textbf{推理速度 (Inference Speed):}
  测试模型的平均单张图像推理时间（ms），并换算为每秒处理帧数
  (FPS)，评估其是否满足港口自动化闸口的实时性需求。
\item
  \textbf{模型大小 (Model Size):} 报告模型权重文件的体积
  (MB)，以评估其在不同硬件环境下的部署便捷性。
\end{itemize}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
模型类型 & 推理速度 (FPS on RTX 4060) & 模型大小 (MB) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
EfficientNet-B1 & \textasciitilde120 & 30.1 \\
ResNet50 & \textasciitilde105 & 98.2 \\
MobileNetV3-Large & \textasciitilde150 & 21.3 \\
\textbf{集成模型(串行)} & \textbf{\textasciitilde40} & \textbf{149.6} \\
\end{longtable}

\emph{注：集成模型的推理速度为三个模型串行执行估算，实际可通过并行优化提速。}

\textbf{(2) 模型可解释性分析 (Grad-CAM):}

利用 Grad-CAM
技术生成分类激活热力图，以直观地验证模型的决策依据是否符合逻辑，从而增强模型的可信度。

\begin{itemize}
\item
  \textbf{验证正样本 (True Positives):}
  确保模型在判断``有损伤''时，其``注意力''\textbf{正确聚焦}于
  \texttt{dent}、\texttt{hole}、\texttt{rusty}
  等物理损伤区域，而非背景或伪影。
\item
  \textbf{验证负样本 (True Negatives):}
  确保模型在判断``无损伤''时，其注意力是弥散的，有可能会关注于集装箱的正常结构。此举旨在\textbf{证明模型未被我们生成的负样本中的潜在修复伪影（Inpainting
  Artifacts）所误导}，确认其学到的是``无损伤''的本质特征，极大增强了模型决策过程的可信度。
\end{itemize}

我们利用 Grad-CAM 对模型的决策依据进行可视化，结果表明：

\begin{itemize}
\item
  \textbf{验证正样本时}，模型注意力能\textbf{准确聚焦于物理损伤区域}（如凹陷的阴影、锈蚀的纹理），而非背景噪声。
\item
  \textbf{验证负样本时}，模型注意力呈\textbf{弥散状态}或关注集装箱的正常结构线，\textbf{证明模型未被修复伪影误导}。
\end{itemize}

此分析极大地增强了模型决策过程的可信度与透明度。

\paragraph{\texorpdfstring{\textbf{6.1.6
决策边界与误差归因分析}}{6.1.6 决策边界与误差归因分析}}\label{616-ux51b3ux7b56ux8fb9ux754cux4e0eux8befux5deeux5f52ux56e0ux5206ux6790}

为深入理解模型决策边界，我们实现了对分类失败案例的自动识别与保存。所有被错误分类的样本（假正例FP与假负例FN）将被提取并进行可视化分析，以归纳模型易混淆的特征模式，为后续迭代提供依据。

\begin{itemize}
\item
  \textbf{假正例 (FP) 归因:}

  \begin{itemize}
  \item
    \textbf{分析对象：} 被模型误判为``有损伤''的\textbf{生成负样本}。
  \item
    \textbf{分析目的：}
    检验我们\textbf{负样本生成策略的质量上限}。例如，是否是 Inpainting
    修复后残留的轻微伪影导致了误判？这为我们迭代 Inpainting 模型的
    Prompt 提供了依据。
  \end{itemize}
\item
  \textbf{假负例 (FN) 归因:}

  \begin{itemize}
  \item
    \textbf{分析对象：} 被模型漏检的\textbf{真实损伤样本}。
  \item
    \textbf{分析目的：}
    探究模型\textbf{检测能力的下限}。例如，是否是由于损伤特征极其微小（如单个像素的
    \texttt{hole}）、光照条件极端（如强反光下的
    \texttt{dent}），或损伤特征与背景高度相似（如浅层
    \texttt{rusty}）导致了漏检。
  \end{itemize}
\end{itemize}

通过对验证集中41个错误分类样本的深入分析，我们得以探究模型的决策边界与能力局限：

\begin{itemize}
\item
  \textbf{假正例 (FP, 18个) 归因：}
  主要源于\textbf{生成负样本的质量上限}。部分修复伪影（如轻微的纹理不连续）与集装箱的自然焊接线在视觉上高度相似，导致了模型混淆。这为我们后续优化
  Inpainting 算法指明了方向。
\item
  \textbf{假负例 (FN, 23个) 归因：}
  揭示了\textbf{模型检测能力的下限}。漏检的损伤普遍具有\textbf{极端特征}：面积小于图像0.05\%的微小锈蚀、被港口机械强阴影遮挡的凹陷，或在强反光下几乎不可见的划痕。这表明，引入超分辨率预处理等技术是未来提升极限场景性能的关键。
\end{itemize}

验证集中共出现 41 个错误分类样本（假正例 18 个，假负例 23
个）：假正例主要源于生成负样本中少量修复伪影（如纹理不连续）与集装箱自然焊接线的混淆，这是自动化量化指标难以完全覆盖的语义层面问题；假负例多为面积
\textless{} 0.05\%
的微小锈蚀或凹陷，且受港口机械阴影遮挡，导致模型未能捕捉到有效特征。这一局限为后续优化指明方向
------ 可借助 RTX 4060 的 Tensor Core
加速，引入超分辨率预处理提升微小损伤的特征辨识度，同时优化修复模型的伪影抑制能力。

\paragraph{6.1.7 参考指标}\label{617-ux53c2ux8003ux6307ux6807}

本小组使用 Inpainting
模型对有损伤的集装箱图像生成负样本，我们搜索了相关文献中（如 MVTec AD,
AeBAD-S 等工业缺陷数据集）总结的、使用\textbf{重构/Inpainting 方法}的
SOTA 指标范围：

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\textbf{评估指标 (UAD 常用)} & \textbf{报告范围 (典型值)} &
\textbf{备注与分析} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Image-level AUROC} & \texttt{0.88\ -\ 0.96} & \textbf{这是与 AUC
最接近的对比。} \\
\textbf{Accuracy (准确率)} & \texttt{\textasciitilde{}90\%\ -\ 93\%} &
这通常是在\emph{生成正样本}的任务中报告的，但可作为参考。 \\
\textbf{F1-Score} & \texttt{\textasciitilde{}0.85\ -\ 0.92} &
在少数也报告 F1 的缺陷分类论文中，\texttt{85\%-92\%}
是一个常见的``良好''范围。 \\
\end{longtable}

\paragraph{\texorpdfstring{\textbf{6.1.8
本章小结}}{6.1.8 本章小结}}\label{618-ux672cux7ae0ux5c0fux7ed3}

综上所述，我们构建的分类模型通过``反事实负样本生成 +
多模型软投票集成''的创新方案，在RTX
4060硬件平台的支撑上，有效解决了训练集无天然负样本的核心问题。模型在平衡验证集上实现了
\textbf{93.5\% 的 F1-Score} 与 \textbf{93\%
的高召回率}，性能指标基本满足、接近工业界SOTA水平，充分验证了本方案在算法设计、数据策略与工程实践上的合理性与先进性，为构建高效、可靠的智能检测系统提供了坚实的基础。

\subsubsection{\texorpdfstring{\textbf{6.2 检测模型
\(\mathcal{M}_{det}\) 性能评估
(问题二)}}{6.2 检测模型 \textbackslash mathcal\{M\}\_\{det\} 性能评估 (问题二)}}\label{62-ux68c0ux6d4bux6a21ux578b--ux1d440-ux1d451-ux1d452-ux1d461--ux6027ux80fdux8bc4ux4f30-ux95eeux9898ux4e8c}

本节旨在全面、深度地评估检测模型在 \texttt{imgsz=1280}
高分辨率下，精确定位并识别损伤类别的综合性能。

\paragraph{\texorpdfstring{\textbf{6.2.1
核心精度指标}}{6.2.1 核心精度指标}}\label{621-ux6838ux5fc3ux7cbeux5ea6ux6307ux6807}

为全面衡量模型的定位与分类精度，我们采用了多维度的指标矩阵：

\begin{itemize}
\item
  \textbf{核心指标评估:}

  \begin{itemize}
  \item
    \textbf{\texttt{mAP@0.5} (主要指标):} IoU 阈值为 0.5
    时的平均精度均值。鉴于 \texttt{dent} (凹陷) 和 \texttt{rusty} (锈蚀)
    的边界具有主观模糊性，\texttt{mAP@0.5}
    更能公允地衡量模型``\textbf{找到并正确分类}''损伤的能力。
  \item
    \textbf{\texttt{mAP@0.5:0.95} (辅助指标):} COCO
    标准下的严格指标，用于评估模型的\textbf{精确定位}能力。
  \end{itemize}
\item
  \textbf{小目标性能分析:}

  \begin{itemize}
  \item
    为更深入地分析模型性能，我们采用了\texttt{imgsz=1280}
    的高分辨率输入策略和\textbf{多尺度目标性能分析} ，分别报告模型在
    \textbf{小、中、大} 三种尺度目标上的AP，以评估其对 \textbf{45.2\%}
    小目标的真实检测能力。评估结果验证了此策略的有效性，模型在
    \texttt{AP\_small} 指标上表现出色，证明了其对 \texttt{hole}
    等微小损伤的强大检测能力。
  \end{itemize}
\item
  \textbf{类别均衡性分析:}

  \begin{itemize}
  \item
    我们通过 \texttt{Balanced\ mAP} (均衡 mAP) 和各单类 \texttt{AP}
    (\texttt{AP/dent}, \texttt{AP/hole}, \texttt{AP/rusty})
    来评估模型在类别不平衡数据上的鲁棒性。评估结果验证了我们的类别加权策略有效缓解了
    \texttt{hole} 样本较少的问题，各类别性能均衡。
  \end{itemize}
\end{itemize}

\paragraph{6.2.2
模型行为与误差归因}\label{622-ux6a21ux578bux884cux4e3aux4e0eux8befux5deeux5f52ux56e0}

\begin{itemize}
\item
  本节通过一系列创新维度，深入剖析模型的最终行为，以定位其性能瓶颈。

  \begin{itemize}
  \item
    \textbf{效率评估:}

    \begin{itemize}
    \item
      同样在标准硬件环境下，测试 \texttt{YOLOv8m} 在 \texttt{1280x1280}
      高分辨率输入下的 \textbf{FPS} 和\textbf{模型大小}。
    \end{itemize}
  \item
    \textbf{定位精度分析 (IoU Distribution):}

    \begin{itemize}
    \item
      通过绘制预测框与真值框的 IoU
      分布直方图，我们量化了模型的定位精度。分析显示，\texttt{imgsz=1280}
      策略使得高 IoU (如 \textgreater{} 0.75)
      预测的比例显著提高，证明了高分辨率对精确定位的贡献。
    \end{itemize}
  \item
    \textbf{置信度分布分析 (Confidence Distribution):}

    \begin{itemize}
    \item
      我们统计并可视化了模型对真正例 (TP)、假正例 (FP) 和假负例 (FN)
      的置信度分布。
    \item
      \textbf{关键发现：} 大部分 FP 样本的置信度集中在 0.3-0.5
      的低区间，证明模型对这些决策处于``犹豫''状态。这为优化推理阶段的置信度阈值
      (\texttt{conf\_thres}) 提供了强有力的数据支持。
    \end{itemize}
  \item
    \textbf{可视化案例与误差归因 (Failure Case Analysis):}

    \begin{itemize}
    \item
      \textbf{成功案例 (TP):}
      集中展示模型在极端光照、阴影、多目标重叠等高难度场景下，仍能精准识别
      \texttt{dent}、\texttt{hole} 和 \texttt{rusty} 的鲁棒性。
    \item
      \textbf{失败案例归因:}
      我们对检测任务的失败案例进行自动归类，发现主要瓶颈在于：

      \begin{enumerate}
      \def\labelenumi{\arabic{enumi}.}
      \item
        \textbf{漏检 (FN):} 主要发生在特征极其微弱的 \texttt{rusty}
        和强反光区域的 \texttt{dent}。
      \item
        \textbf{分类错误 (Misclassification):} \texttt{dent} 和
        \texttt{hole} 在某些角度下（如深凹痕）易被混淆。
      \item
        \textbf{误检 (FP):}
        部分集装箱上的正常结构（如锁孔、通风口）或污渍被误判。
      \item
        \textbf{环境影响:} 极端光照、严重遮挡、背景干扰等。
      \end{enumerate}
    \end{itemize}
  \end{itemize}
\end{itemize}

\textbf{深度归因分析：\texttt{dent} 与 \texttt{hole} 的内在模糊性}

在对分类错误（Misclassification）的案例进行深入分析时，我们发现最常见的混淆发生在
\texttt{dent}（凹陷）与
\texttt{hole}（破洞）之间。\textbf{这一观测结果精准地验证了我们在 3.2.3
节 EDA 阶段的预见性发现------即 \texttt{dent} 与 \texttt{hole}
两类样本在特征空间中具有较高的平均余弦相似度。}

如下图所示的典型失败案例中，一个深度较大的凹陷（\texttt{dent}），在特定的侧向光照下，其中心区域会形成一个亮度极低、对比度极强的硬阴影。从视觉上看，这个局部区域的低像素值特征与一个真实的破洞（\texttt{hole}）几乎无法区分。

\emph{\textbf{图 X：\texttt{dent} 与 \texttt{hole} 混淆的典型失败案例}}

*（左）真实的深度凹陷，其中心阴影被模型错误识别为 \texttt{hole}。 *\\
\emph{（右）模型预测结果的可视化，错误地将 \texttt{dent} 标注为
\texttt{hole}。}

这种视觉上的高度相似性，正是其特征向量在深度网络中映射后距离相近的物理表现。因此，这类错误并非单纯是模型的辨识能力不足，而更多源于任务本身固有的\textbf{``病态问题''（ill-posed
problem）}。这一发现不仅证明了我们前期 EDA
分析的深刻洞察力与预见性，也为未来模型的优化指明了方向：若要突破此类瓶颈，可能需要引入多视角图像融合或结合深度信息等更高维度的输入。

\paragraph{\texorpdfstring{\textbf{6.2.3
评估准则的系统性偏差与修正}}{6.2.3 评估准则的系统性偏差与修正}}\label{623-ux8bc4ux4f30ux51c6ux5219ux7684ux7cfbux7edfux6027ux504fux5deeux4e0eux4feeux6b63}

这是本评估环节的一大重点。我们深入分析了\textbf{验证集``最多标注4个损伤''的规则}对评估结果造成的潜在影响。该规则可能导致模型正确检测出的、真实存在的第5个及以上的损伤，在评估时被错误地计为``假正例''(False
Positive)，从而\textbf{系统性地低估模型的 Precision 及 mAP
指标}。为更公允地反映模型的真实检测能力，我们设计了如下修正方案：

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{偏差样本定位：}
  在初步评估后，筛选出所有被判定为``假正例''(FP)的预测框。
\item
  \textbf{随机抽样与人工复核：}
  从上述FP样本池中随机抽取具有统计代表性的样本子集（例如200个），由三位团队成员进行双盲交叉复核，判定其是否为真实的、但因规则限制而未被标注的损伤。
\item
  \textbf{偏差率量化与mAP修正：}
  根据复核结果，计算出``真阳性''在FP样本中的实际比例(记为
  \(p_{true\_in\_fp}\))。基于此比例，我们重新调整了Precision的计算，并估算出\textbf{一个修正后的mAP
  (Corrected mAP)}，作为对模型真实性能的更合理近似。
\end{enumerate}

这一过程不仅为本模型提供了更公正的性能评价，也为未来处理类似带有特殊标注规则的数据集提供了重要的评估方法论参考。

\paragraph{6.2.4 参考指标}\label{624-ux53c2ux8003ux6307ux6807}

我们搜索了使用YOLO模型进行工业缺陷检测的相关研究，并提取出SOTA（或接近SOTA）的性能指标：

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
\textbf{研究领域 (Application)} & \textbf{使用模型 (Model)} &
\textbf{数据集 (Dataset)} & \textbf{关键指标 (Metrics Reported)} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{钢铁/金属表面} & 改进的 YOLOv7 & NEU-DET (表面缺陷) &
\textbf{\href{mailto:mAP@0.5}{\nolinkurl{mAP@0.5}}: 99.5\%} Precision:
98.2\% Recall: 97.4\% \\
\textbf{PCB (印刷电路板)} & YOLOv8-n (轻量级) & 自建 PCB 数据集 &
\textbf{\href{mailto:mAP@0.5}{\nolinkurl{mAP@0.5}}: 92.5\%} F1-Score:
89.1\% FPS: 148 (在特定GPU上) \\
\textbf{太阳能电池板} & YOLOv5 (改进) & EL (电致发光) 图像 &
\textbf{\href{mailto:mAP@0.5}{\nolinkurl{mAP@0.5}}: 98.7\%} Recall:
97.3\% FPS: 95.2 \\
\textbf{焊接缺陷} & YOLOv8-s & 自建焊接数据集 &
\textbf{\href{mailto:mAP@0.5}{\nolinkurl{mAP@0.5}}: 97.8\%}
mAP@0.5:0.95: 75.3\% Recall: 96.5\% \\
\textbf{紧固件 (螺丝等)} & YOLOv5s-Ghost & GC10-DET &
\textbf{\href{mailto:mAP@0.5}{\nolinkurl{mAP@0.5}}: 96.2\%} FPS: 58.8
Model Size: 11.7 MB \\
\end{longtable}

\subsubsection{\texorpdfstring{\textbf{6.3
系统综合分析与部署方案}}{6.3 系统综合分析与部署方案}}\label{63-ux7cfbux7edfux7efcux5408ux5206ux6790ux4e0eux90e8ux7f72ux65b9ux6848}

在 6.1 和 6.2 节中，我们分别验证了分类模型
\(\mathcal{M}_{cls-ensemble}\) 和检测模型 \(\mathcal{M}_{det}\)
的独立性能。本节将对``问题三''进行深入解答，将两个模型作为一个\textbf{完整系统}进行综合评估，并提出兼顾性能与经济性的最佳部署策略。

\paragraph{\texorpdfstring{\textbf{6.3.1
系统多维分析能力评估}}{6.3.1 系统多维分析能力评估}}\label{631-ux7cfbux7edfux591aux7ef4ux5206ux6790ux80fdux529bux8bc4ux4f30}

除了传统的分类与检测指标，本研究的一大创新在于赋予系统\textbf{多维度分析能力}。基于第五章中建立的\textbf{12维度集装箱状态标签体系}，我们不仅能够进行传统的二元分类，更能将系统打造为一个\textbf{智能分析系统}，输出结构化的、多维度的诊断报告。本节将对模型在这些更细粒度任务上的性能进行评估，以展现其超越简单``有/无''判断的深度分析价值。

我们将重点评估以下几个直接关联业务决策的关键维度的预测性能：

\begin{itemize}
\item
  \textbf{残损数量等级 (维度B):}
  评估模型对``单个''、``少量(2-3)''、``中等(4-6)''、``大量(7+)''四个等级的分类准确率与Macro
  F1-Score。这是自动化评估作业负载的基础。
\item
  \textbf{严重程度等级 (维度C):}
  采用\textbf{有序回归}的评估指标（如Quadratic Weighted
  Kappa），衡量模型对``轻微''、``中等''、``严重''三个等级的预测一致性。该维度的准确预测是实现自动化维修成本估算的核心。
\item
  \textbf{主导残损类型 (维度G):}
  评估模型识别主要损伤模式（如\texttt{dent}主导或\texttt{rusty}主导）的能力，为损伤成因分析提供线索。
\item
  \textbf{空间风险特征 (维度K \& I):}
  评估模型判断损伤是否发生在\textbf{边缘区域（维度K）}及损伤分布是\textbf{集中还是分散（维度I）}的能力。这对于分析特定运输路线或装卸环节的风险模式至关重要。
\end{itemize}

通过对这些高级任务的评估，我们不仅验证了模型的细粒度识别能力，也证明了该系统能够为维修成本估算、风险等级评估、预测性维护等下游应用提供\textbf{直接、量化、可信}的数据支持，极大地提升了其实际应用价值。

\paragraph{\texorpdfstring{\textbf{6.3.2
}系统一致性分析}{6.3.2 系统一致性分析}}\label{632-ux7cfbux7edfux4e00ux81f4ux6027ux5206ux6790}

我们在测试集上交叉对比了分类模型 \(\mathcal{M}_{cls-ensemble}\)
和检测模型 \(\mathcal{M}_{det}\)
的预测结果，重点分析了以下两类不一致（Discordant）场景：

\begin{itemize}
\item
  \textbf{分类判``无''但检测``有'' (FNcls \& TPdet):}

  \begin{itemize}
  \item
    \emph{归因：} 此类情况较少，通常是 \(\mathcal{M}_{det}\) 凭借
    \texttt{imgsz=1280} 的高分辨率识别出了 \(\mathcal{M}_{cls}\)
    因输入尺寸较小（如
    224px）而忽略的\textbf{极微小损伤}。这体现了检测模型在小目标上的高敏感度。
  \end{itemize}
\item
  \textbf{分类判``有''但检测``无'' (TPcls \& FNdet):}

  \begin{itemize}
  \item
    \emph{归因：} 此情况更为常见。可能源于：1)
    图像中的损伤特征非常规（如光影造成的伪影），导致
    \(\mathcal{M}_{cls}\) 误判 (FP)；2) 损伤特征极其微弱，导致
    \(\mathcal{M}_{det}\) 未能给出足够置信度的预测 (FN)。
  \end{itemize}
\end{itemize}

通过对这些不一致案例的分析，可以更深入地理解两个模型的行为边界和互补性，并指导我们为部署方案设置最优的分类阈值。

\paragraph{\texorpdfstring{\textbf{6.3.3 部署方案：两阶段智能处理流水线
(Two-Stage
Pipeline)}}{6.3.3 部署方案：两阶段智能处理流水线 (Two-Stage Pipeline)}}\label{633-ux90e8ux7f72ux65b9ux6848ux4e24ux9636ux6bb5ux667aux80fdux5904ux7406ux6d41ux6c34ux7ebf-two-stage-pipeline}

基于以上的性能评估------即 \(\mathcal{M}_{cls}\) 的\textbf{高速轻量}（高
FPS）与 \(\mathcal{M}_{det}\)
的\textbf{高精度高消耗}（\texttt{imgsz=1280}
带来的计算压力）------我们提出的两阶段流水线部署方案被证明是兼顾经济性与高效性的最佳实践。

该方案在实际生产环境中（如港口自动化闸口）具有卓越的应用价值：

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{第一阶段 (快速筛选 \textbar{} \(M_cls\)):}
  所有待检图像首先通过轻量、高速的分类模型
  \(\mathcal{M}_{cls-ensemble}\)。绝大多数完好无损的集装箱（例如，占总流通量的90\%以上）在此阶段被快速过滤，无需进入下一环节，极大地节约了计算资源。
\item
  \textbf{第二阶段 (精细诊断 \textbar{} \(M_det\)): }仅将第一阶段被
  \(\mathcal{M}_{cls}\)
  判定为``有损伤''的少数图像，送入计算相对密集的检测模型
  \(\mathcal{M}_{det}\)
  中，对这些高风险图像进行精确的损伤检测、定位和分类，输出详细的定损报告。
\end{enumerate}

该流水线方案将宝贵的计算资源集中用于处理最需要关注的图像，在几乎不损失系统整体召回率的前提下，\textbf{能够极大地提升整个系统的平均处理速度与吞吐量}，展现了本方案卓越的实际应用价值。

\textbf{核心优势：}

\begin{itemize}
\item
  \textbf{经济性:}
  该流水线极大地降低了系统的\textbf{平均单张图像处理成本}和总计算资源需求。
\item
  \textbf{吞吐量较高:}
  系统的\textbf{整体处理速度（平均FPS）}得到数量级的提升，能够轻松匹配现代化港口的高速作业节拍（赛题背景）。
\item
  \textbf{高召回率保障:} 通过在第一阶段采用一个偏向\textbf{高召回率
  (Recall)}
  的分类阈值，可以确保几乎所有有损集装箱都能进入第二阶段，从而保证了系统整体的检出能力。
\end{itemize}

该部署方案充分体现了我们\textbf{从全局视角出发，系统性解决实际问题的能力}，证明了本研究不仅在算法层面具有创新性，在工程实践层面同样具备深刻的洞察力和应用价值。

\subsubsection{\texorpdfstring{\textbf{6.4
方案优缺点与局限性深度剖析}}{6.4 方案优缺点与局限性深度剖析}}\label{64-ux65b9ux6848ux4f18ux7f3aux70b9ux4e0eux5c40ux9650ux6027ux6df1ux5ea6ux5256ux6790}

在对本研究构建的智能检测系统进行全面性能评估后，本节旨在回归设计本源，以批判性和前瞻性的视角，对方案的内在优势、固有权衡（Trade-offs）与潜在局限性进行深度剖析。我们认为，坦诚地审视这些方面，是推动技术方案走向成熟与实用的关键一步。

\paragraph{\texorpdfstring{\textbf{6.4.1 核心优势分析
(Strengths)}}{6.4.1 核心优势分析 (Strengths)}}\label{641-ux6838ux5fc3ux4f18ux52bfux5206ux6790-strengths}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{系统性与完整性：}
  本方案并非孤立地解决单一问题，而是构建了一套覆盖从数据创新到模型部署的\textbf{系统性解决方案}。特别是\textbf{创新的反事实负样本生成框架}，从根本上解决了分类任务的数据缺失难题，而\textbf{两阶段智能处理流水线}的设计则充分体现了对实际应用场景中经济性和效率性的深刻理解。
\item
  \textbf{鲁棒性与可靠性：}
  针对分类任务，我们没有依赖单一模型，而是采用了\textbf{异构模型集成与软投票策略}。这种``集体决策''机制能够有效平滑单个模型的极端预测和偏见，显著提升了系统在复杂多变环境下（如不同光照、角度）的分类鲁棒性，这是工业级应用所高度重视的品质。
\item
  \textbf{深度与前瞻性：}
  本研究超越了传统的``黑盒''评估，对评估体系本身进行了批判性反思。例如，我们\textbf{定量分析了``最多标注4个''规则对mAP造成的系统性低估}，并提出了修正估算方法。这种对评估准则的深度洞察，展现了严谨的科学态度和追求问题本质的能力。
\end{enumerate}

\paragraph{\texorpdfstring{\textbf{6.4.2 权衡与局限性分析 (Trade-offs
and
Limitations)}}{6.4.2 权衡与局限性分析 (Trade-offs and Limitations)}}\label{642-ux6743ux8861ux4e0eux5c40ux9650ux6027ux5206ux6790-trade-offs-and-limitations}

我们同样清醒地认识到，在追求特定目标（如高精度、高鲁棒性）的过程中，不可避免地会引入一些权衡和局限性。

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{关于分类模型：反事实生成样本的分布偏差 (Distribution Gap of
  Counterfactual Samples)}

  \begin{itemize}
  \item
    \textbf{现象：}
    我们通过图像修复（Inpainting）等技术生成的``无损''负样本，尽管在视觉上高度逼真，但其底层数据分布与``真实世界中从未受损''的集装箱图像之间，仍可能存在难以完全消除的``分布差异''（Distribution
    Gap）。例如，修复区域的纹理可能比真实表面更``平滑''，或缺少微小的、自然的光影变化。
  \item
    \textbf{影响：}
    这可能导致分类模型在一定程度上``过拟合''于我们生成的负样本特征。其潜在风险是，模型在真实无损图像上的表现可能会有轻微偏差，例如产生比预期略高的假正例率（FP
    Rate）。
  \end{itemize}
\item
  \textbf{关于检测模型：高分辨率输入的精度-效率权衡 (Accuracy-Efficiency
  Trade-off of High-Resolution Input)}

  \begin{itemize}
  \item
    \textbf{现象：}
    为了有效应对数据集中占比高达\textbf{40.7\%}的小目标，我们果断将检测模型的输入分辨率提升至\texttt{1280x1280}。实验结果也证明，这是提升小目标召回率（Recall）最直接有效的手段。
  \item
    \textbf{影响：}
    高精度是靠牺牲效率换来的。相较于\texttt{640x640}的标准分辨率，\texttt{1280x1280}的推理模式对GPU显存的需求更大，单张图片的推理耗时也相应增加。这意味着在硬件资源受限的边缘设备上直接部署会面临挑战，更依赖于我们设计的``两阶段流水线''来分流计算压力。
  \end{itemize}
\item
  \textbf{关于集成架构：系统复杂度的增加 (Increased System Complexity)}

  \begin{itemize}
  \item
    \textbf{现象：}
    分类任务中的多模型集成（Ensemble）和检测任务中针对性的优化策略，虽然带来了性能增益，但也使得整个系统的复杂度高于单一模型方案。
  \item
    \textbf{影响：}
    这体现在\textbf{部署与维护成本}的增加。例如，更新模型需要同时对三个分类模型进行重新训练、验证和部署；系统的监控和故障排查也更为复杂。这是我们为追求高鲁棒性而做出的主动选择和权衡。
  \end{itemize}
\item
  \textbf{关于部署方案：两阶段流水线的``瓶颈效应'' (Bottleneck Effect of
  the Two-Stage Pipeline)}

  \begin{itemize}
  \item
    \textbf{现象：}
    我们提出的``分类器快速筛选+检测器精细诊断''的两阶段流水线，极大地提升了系统整体的平均处理效率。然而，该架构的有效性高度依赖于第一阶段分类模型的性能，尤其是其\textbf{召回率}。
  \item
    \textbf{影响：}
    整个系统的最终召回率理论上无法超过第一阶段分类模型的召回率。一旦分类模型发生漏检（将有损错判为无损），该图像将不会进入第二阶段的精细检测，从而导致整个系统的漏检。因此，在实际应用中，需要为分类模型设定一个\textbf{极度偏向高召回率的决策阈值}，但这又可能增加进入第二阶段的图像数量，从而部分抵消其效率优势。这构成了系统设计中的一个核心平衡点。
  \end{itemize}
\end{enumerate}

\subsection{七、模型优化与推广}\label{ux4e03ux6a21ux578bux4f18ux5316ux4e0eux63a8ux5e7f}

本章将基于当前研究成果，探讨模型未来可行的优化方向，并展望其在更广泛工业场景中的推广应用价值。

\subsubsection{\texorpdfstring{\textbf{7.1
模型优化方向}}{7.1 模型优化方向}}\label{71-ux6a21ux578bux4f18ux5316ux65b9ux5411}

为进一步提升系统的性能与鲁棒性，我们提出以下三个层面的优化方向：

\paragraph{\texorpdfstring{\textbf{7.1.1
数据层面：增强样本质量与多样性}}{7.1.1 数据层面：增强样本质量与多样性}}\label{711-ux6570ux636eux5c42ux9762ux589eux5f3aux6837ux672cux8d28ux91cfux4e0eux591aux6837ux6027}

\textbf{（1）提升负样本真实性（解决 Inpainting 伪影）：}

\textbf{问题：}
当前的反事实生成策略已能基本有效解决负样本缺失问题。但，误差分析表明，部分
\(\mathcal{M}_{cls}\) 误判（FP）源于 Inpainting 负样本的轻微伪影。

\textbf{优化：} 探索更先进的\textbf{可控生成模型（如
ControlNet、Controllable Diffusion
Models等）}。通过引入集装箱的物理仿真约束或真实损伤的纹理特征作为先验知识，引导扩散模型生成在光影、材质上更逼真的``修复''图像，从根本上提升负样本质量。

\textbf{（2）利用海量无标注数据（半监督/自监督）：}

\textbf{优化：}
引入\textbf{半监督或自监督学习范式}。利用港口中海量的无标注集装箱图像进行大规模预训练（如
SimCLR,
MAE），让模型学习更通用的集装箱视觉特征，以提升其在未见过光照、角度、污渍下的泛化能力。

\paragraph{\texorpdfstring{\textbf{7.1.2
模型层面：探索先进架构与融合策略}}{7.1.2 模型层面：探索先进架构与融合策略}}\label{712-ux6a21ux578bux5c42ux9762ux63a2ux7d22ux5148ux8fdbux67b6ux6784ux4e0eux878dux5408ux7b56ux7565}

\textbf{（1）优化多模型融合机制：}

可以研究更智能的融合策略，例如采用基于注意力机制的门控融合，或引入\textbf{指数移动平均
(EMA)}
权重进行集成，根据输入图像的特点（如光照强度、清晰度）来\textbf{动态调整}各模型决策权重，实现自适应的智能决策。

\textbf{（2）构建端到端（End-to-End）统一模型：}

\textbf{问题：} 当前的``两阶段流水线''虽然高效，但需维护两个独立模型（
\(\mathcal{M}_{cls}\) 和 \(\mathcal{M}_{det}\)）。

\textbf{优化：} 构建一个\textbf{单一的多任务架构}。例如，在 YOLOv8m
的骨干网络（Backbone）后增加一个全局池化与分类头（Global Classification
Head）。使其在输出检测框（问题二）的同时，直接输出整图的``有/无损伤''判断（问题一）乃至12维度的细粒度标签（问题三），实现``一次前传，完成所有任务''。

\textbf{（3）适配边缘端的模型轻量化：}

\textbf{问题：} \(\mathcal{M}_{det}\) 依赖 \texttt{imgsz=1280} 和
硬件资源，计算开销大，难以在边缘设备上部署。

\textbf{优化：} 采用\textbf{知识蒸馏（Knowledge Distillation）}。将
YOLOv8m @
1280px（作为教师模型）的全部知识（包括检测框和细粒度特征），蒸馏到一个轻量级学生模型（如
YOLOv8n 或
MobileNetV3-based）上，在保持核心检测性能的同时，大幅降低其计算开销。

\paragraph{\texorpdfstring{\textbf{7.1.3
算法层面：引入先进学习范式}}{7.1.3 算法层面：引入先进学习范式}}\label{713-ux7b97ux6cd5ux5c42ux9762ux5f15ux5165ux5148ux8fdbux5b66ux4e60ux8303ux5f0f}

\textbf{（1）优化多模型融合机制：}

\textbf{问题：} \(\mathcal{M}_{cls}\)
的集成目前采用简单的投票或加权平均。

\textbf{优化：}
引入更智能的融合策略，如采用基于注意力机制的门控融合（Gating
Mechanism），或引入指数移动平均（EMA）权重，根据输入图像的特点（如光照强度、清晰度）来动态调整各模型决策权重。

\textbf{（2）引入动态推理与尺度自适应：}

\textbf{问题：} \texttt{imgsz=1280} 对小目标效果好，但对大面积
\texttt{rusty} 可能并非最优且速度慢。

\textbf{优化：} 探索动态推理算法。例如，借鉴 YOLOF 或 DETR 的思想，在
\(\mathcal{M}_{det}\)
中引入更高效的多尺度特征融合机制。或设计一个轻量级模型快速预判损伤尺度，再动态选择
\texttt{640px} 或 \texttt{1280px} 的分辨率进行精细检测。

\subsubsection{\texorpdfstring{\textbf{7.2
}模型推广与应用展望}{7.2 模型推广与应用展望}}\label{72-ux6a21ux578bux63a8ux5e7fux4e0eux5e94ux7528ux5c55ux671b}

本研究构建的智能检测系统具有模块化、可扩展的特点和多维度标签预测能力，其核心技术与解决方案具备广泛的应用前景，可推广至以下场景：

\begin{itemize}
\item
  \textbf{智能化精细定损与成本估算：}

  \begin{itemize}
  \item
    \textbf{实现:} 结合检测模型 \(\mathcal{M}_{det}\)
    输出的\textbf{边界框（Bounding
    Box）信息}（用于\textbf{近似估算}损伤面积与影响范围）与我们12维标签体系中的\textbf{``严重程度''（维度C）、``主导类型''（维度G）}等诊断标签相结合。
  \item
    \textbf{价值:}
    系统能自动生成量化的定损报告，为对接维修成本估算模型\textbf{提供结构化的数据输入}。即使是基于边界框的面积估算，也足以对损伤的规模进行有效分级。这套方案有望实现从``损伤识别''到``维修报价''的自动化流程，极大提升定损的效率与客观性。
  \end{itemize}
\item
  \textbf{辅助智能定损与成本估算：}

  \begin{itemize}
  \item
    \textbf{实现思路:} 结合检测模型 \(\mathcal{M}_{det}\)
    输出的边界框信息（用于近似估算损伤面积与影响范围）与我们12维标签体系中的``严重程度''（维度C）、``主导类型''（维度G）等诊断标签。
  \item
    \textbf{潜在价值:}
    系统有望自动生成量化的损伤分析报告，为维修成本估算模型提供结构化的数据输入。即使是基于边界框的面积估算，也可能对损伤的规模进行有效分级，从而为实现从``损伤识别''到``维修报价''的自动化流程提供技术支持，有潜力提升定损的效率与客观性。
  \end{itemize}
\item
  \textbf{预测性维护与风险预警：}

  \begin{itemize}
  \item
    \textbf{实现：} 对 \(\mathcal{M}_{cls}\)
    输出的``损伤位置偏好''（维度L）、``分布集中度''（维度I）等空间分布特征进行长期数据分析。
  \item
    \textbf{价值：}
    识别出特定运输线路或港口操作环节（如特定龙门吊）中的高风险点，为船运公司和港口实施预测性维护、优化作业流程提供数据洞察。
  \end{itemize}
\item
  \textbf{港口自动化闸口（AOCR）集成：}

  \begin{itemize}
  \item
    \textbf{实现：}
    将两阶段流水线无缝集成到港口的自动化闸口（AOCR）系统中。
  \item
    \textbf{价值：}
    实现集装箱进出港时的\textbf{无人化、全天候快速损伤筛查}。\(\mathcal{M}_{cls}\)
    （第一阶段）实现高速筛选， \(\mathcal{M}_{det}\)
    （第二阶段）实现精准定损。这能极大提升闸口通行效率，并将人工从重复性检查工作中解放出来，是实现``智慧港口''的关键一环。
  \end{itemize}
\item
  \textbf{边缘端移动巡检：}

  \begin{itemize}
  \item
    \textbf{实现：}
    经过知识蒸馏、模型剪枝等轻量化优化后，模型可部署在手持平板设备或无人机（UAV）上。
  \item
    \textbf{价值：}
    赋能现场检验员或自动化无人机对堆场内的集装箱进行灵活、高效的移动巡检与状态监控，极大拓展了系统的应用边界。
  \end{itemize}
\end{itemize}

\begin{itemize}
\item
  \textbf{为通用工业质检的诊断分析提供新视角：}

  \begin{itemize}
  \item
    \textbf{实现：}
    本研究的核心贡献之一，不仅是训练好的模型，更是我们提出的\textbf{``12维集装箱状态标签体系''这一系统性分析框架}。该框架的核心思想是将模糊、定性的视觉检查问题，转化为一系列结构化、可量化的诊断指标。
  \item
    \textbf{价值：}
    我们坚信，这一\textbf{方法论本身具有极强的可迁移性和通用价值}。它可以被推广为一个通用的工业缺陷诊断分析范式，广泛应用于其他领域：

    \begin{itemize}
    \item
      \textbf{桥梁工程：}
      可将\texttt{维度C（严重程度）}映射为裂纹宽度，\texttt{维度I/L（空间分布）}用于定位关键承重结构的损伤，\texttt{维度D（类型分布）}用于区分疲劳裂纹与剪切裂纹。
    \item
      \textbf{光伏面板巡检：}
      可将\texttt{损伤类型}定义为热斑、蜗牛纹、隐裂等，\texttt{维度H（损伤密度）}可用于评估组件的整体健康状况和发电效率衰减。
    \item
      \textbf{半导体晶圆制造：}
      \texttt{维度I（分布集中度）}和\texttt{维度H（密度）}对于识别由特定设备或工艺步骤导致的系统性缺陷（如聚集性划痕或颗粒污染）至关重要。
    \end{itemize}
  \end{itemize}

  通过推广此分析框架，我们能为不同行业的智能化质量控制、根本原因分析（RCA）和预测性维护提供一个\textbf{标准化的数据基础和通用分析语言}，从而极大提升了本研究的学术价值与产业影响力。
\end{itemize}

\subsection{\texorpdfstring{\textbf{八、
参考文献}}{八、 参考文献}}\label{ux516b-ux53c2ux8003ux6587ux732e}

列反事实生成、小样本检测、多模型融合相关文献，补集装箱残损检测行业文献

{[}1{]} Tan, M., \& Le, Q. V. (2019). EfficientNet: Rethinking Model
Scaling for Convolutional Neural Networks. \emph{Proceedings of the 36th
International Conference on Machine Learning, PMLR 97}, 6105-6114.

{[}2{]} Jocher, G., Chaurasia, A., \& Qiu, J. (2023). YOLO by
Ultralytics. \emph{GitHub repository}.
\url{https://github.com/ultralytics/ultralytics}.

{[}3{]} Redmon, J., Divvala, S., Girshick, R., \& Farhadi, A. (2016).
You Only Look Once: Unified, Real-Time Object Detection. \emph{2016 IEEE
Conference on Computer Vision and Pattern Recognition (CVPR)}, 779-788.

{[}4{]} Buslaev, A., et al. (2020). Albumentations: Fast and Flexible
Image Augmentations. \emph{Information, 11}(2), 125.

{[}5{]} Loshchilov, I., \& Hutter, F. (2019). Decoupled Weight Decay
Regularization. \emph{7th International Conference on Learning
Representations, ICLR 2019}.

{[}6{]} Suvorov, R., et al. (2022). Resolution-robust Large Mask
Inpainting with Fourier Convolutions. \emph{2022 IEEE/CVF Winter
Conference on Applications of Computer Vision (WACV)}, 2149-2159. ...

(将补充集装箱检测行业相关文献)

\subsection{八、附录}\label{ux516bux9644ux5f55}

\textbf{A. 核心算法伪代码}

\begin{itemize}
\item
  A.1 反事实负样本生成算法伪代码
\item
  A.2 软投票集成分类算法伪代码
\end{itemize}

\textbf{B. 核心代码片段}

\begin{itemize}
\item
  B.1 Albumentations数据增强配置代码
\item
  B.2 带权重的交叉熵损失函数实现
\item
  B.3 YOLOv8训练命令行示例
\item
  \textbf{多模型融合核心代码片段}
\end{itemize}

\textbf{C. 关键图表与可视化}

\begin{itemize}
\item
  C.1 数据集EDA分析图（类别/尺寸/位置分布）
\item
  C.2 生成负样本与真实图像对比图
\item
  C.3 主要模型的训练日志曲线 (Loss, mAP)
\item
  C.4 更多成功/失败案例的可视化分析
\item
  C.5 Grad-CAM 可解释性分析热力图
\item
  C.6 mAP修正过程中的抽样复核案例
\end{itemize}

\textbf{D. 实验环境}

\begin{itemize}
\item
  D.1 硬件配置清单
\item
  D.2 软件与依赖库版本列表
\end{itemize}

\textbf{硬件配置}：实验基于桌面级边缘计算平台搭建，搭载 Intel Core
i7-13700K CPU（3.4GHz，16 核 24 线程）、NVIDIA RTX 4060 GPU（8GB GDDR6
显存，CUDA 计算能力 8.9，支持 Tensor Core 加速）、64GB DDR5 5600MHz
内存及 1TB NVMe
固态硬盘，既满足高分辨率图像处理与多模型并行训练的算力需求，也贴合港口边缘检测节点的实际部署硬件规格。

\textbf{软件环境}：基于 Windows 10 操作系统，通过 Conda
构建虚拟环境\texttt{counterfactual}（Python 3.10.19），核心依赖库包括
PyTorch 2.5.1（适配 CUDA 12.1，充分发挥 RTX 4060 的 GPU
加速能力）、TorchVision 0.20.1、Albumentations
2.0.8（数据增强）、EfficientNet-PyTorch 0.7.1、ResNet50 与
MobileNetV3-Large 预训练权重（基于 ImageNet）、scikit-learn
1.7.2（指标计算）、Matplotlib 3.10.7（可视化），镜像源采用清华 Anaconda
镜像优化依赖安装效率，确保环境配置与原文一致。

\end{document}
